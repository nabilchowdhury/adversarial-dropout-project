{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTAdD.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UdoHEU7TZM3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adversarial Dropout Code\n",
        "#### This file contains the code used to replicate the results of Adversarial Dropout"
      ]
    },
    {
      "metadata": {
        "id": "yNPBWy4_vAu3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d0G1RJtjY5gx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "4WzEOO-77L24",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 123456\n",
        "rng = np.random.RandomState(SEED)\n",
        "\n",
        "\n",
        "def __createWeights(shape, seed=None, name='weight'):\n",
        "    w_init = tf.contrib.layers.variance_scaling_initializer(seed=seed)\n",
        "    return tf.get_variable(name + '_w', shape=shape, initializer=w_init)\n",
        "    \n",
        "\n",
        "def __createBiases(size, name='bias'):\n",
        "    return tf.get_variable(name + '_b', shape=[size], initializer=tf.constant_initializer(0.0))\n",
        "\n",
        "def ReLU(x):\n",
        "    x = tf.nn.relu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def LeakyReLU(x, alpha=0.1):\n",
        "    x = tf.nn.leaky_relu(x, alpha=alpha)\n",
        "    return x\n",
        "\n",
        "\n",
        "def MaxPooling(x, ksize=2, stride_length=2, padding='SAME', data_format='NHWC'):\n",
        "    x = tf.nn.max_pool(x, (1, ksize, ksize, 1), (1, stride_length, stride_length, 1), padding, data_format)\n",
        "    return x\n",
        "\n",
        "\n",
        "def GlobalAveragePooling(x):\n",
        "    x = tf.reduce_mean(x, [1, 2])\n",
        "    return x\n",
        "\n",
        "\n",
        "def Dense(x, input_dim, output_dim, seed=None, name='dense'):\n",
        "    W = __createWeights([input_dim, output_dim], seed, name) \n",
        "    b = __createBiases(output_dim, name) \n",
        "    x = tf.nn.xw_plus_b(x, W, b)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Conv2D(x, filter_size, n_channels, n_filters, stride_length=1, padding='SAME', data_format='NHWC', name='conv'):\n",
        "    shape = [filter_size, filter_size, n_channels, n_filters]\n",
        "    W = __createWeights(shape, name=name)\n",
        "    b = __createBiases(n_filters, name=name)\n",
        "    x = tf.nn.conv2d(x, filter=W, strides=(1, stride_length, stride_length, 1), padding=padding, data_format=data_format)\n",
        "    x += b\n",
        "    return x\n",
        "\n",
        "\n",
        "def Dropout(x, rate=0.5, is_train=True):\n",
        "    x = tf.layers.dropout(x, rate=rate, seed=rng.randint(SEED), training=is_train)\n",
        "    return x\n",
        "\n",
        "\n",
        "def GaussianNoise(x, sigma=0.15):\n",
        "    noise = tf.random_normal(shape=tf.shape(x), stddev=sigma)\n",
        "    x += noise\n",
        "    return x\n",
        "\n",
        "\n",
        "def SoftMax(x):\n",
        "    x = tf.nn.softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Loss functions. Arg 1: Approximation, Arg 2: Labels\n",
        "'''\n",
        "def CrossEntropyWithLogits(logits, labels):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Formula: sum(p_i * log(p_i) - p_i * log(q_i))\n",
        "def KLDivergenceWithLogits(q, p):\n",
        "    p_soft = SoftMax(p)\n",
        "    # plogp = tf.reduce_mean(tf.reduce_sum(p_soft * tf.nn.log_softmax(p), 1))\n",
        "    # plogq = tf.reduce_mean(tf.reduce_sum(p_soft * tf.nn.log_softmax(q), 1))\n",
        "    distance = tf.reduce_sum(p_soft * tf.nn.log_softmax(p) - p_soft * tf.nn.log_softmax(q))\n",
        "    # distance = plogp - plogq\n",
        "    return distance\n",
        "  \n",
        "def Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='bn'):\n",
        "    x = tf.layers.batch_normalization(x, axis=axis, training=is_train, momentum=momentum, name=name)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aeUAt_IUZbo4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building blocks for creating the networks"
      ]
    },
    {
      "metadata": {
        "id": "5YRC1mFK7RKs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "The model before AdD is applied\n",
        "'''\n",
        "def upperBlock(x, conv_size=[32, 64, 128], n_channels=3, is_train=True):\n",
        "    x = Conv2D(x, filter_size=3, n_channels=n_channels, n_filters=conv_size[0], padding='SAME', name='1a')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=is_train, momentum=0.999, name='1bna')\n",
        "    x = ReLU(x)\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "    x = Dropout(x, 0.5, is_train)\n",
        "    \n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[1], name='2a')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=is_train, momentum=0.999, name='2bna')\n",
        "    x = ReLU(x)\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "    x = Dropout(x, 0.5, is_train)\n",
        "\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[2], padding='SAME', name='3a')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=is_train, momentum=0.999, name='3bna')\n",
        "    x = ReLU(x)\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "    \n",
        "    x = tf.reshape(x, [-1, 2048], name='reshaped')\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "'''\n",
        "The model after AdD is applied\n",
        "'''\n",
        "def lowerBlock(x, n_in=2048, n_out=10, name='fc'):\n",
        "    x = Dense(x, n_in, 625, name=name + '_1')\n",
        "    x = Dense(x, 625, n_out, name=name + '_2')\n",
        "    return x;\n",
        "\n",
        "\n",
        "'''\n",
        "Apply adv dropout\n",
        "'''\n",
        "def advDropout(x, Jacobian, rate=0.5, sigma=0.05, dim=2048, is_train=True):\n",
        "    # y: output \n",
        "    # mask: current sampled dropout mask \n",
        "    # sigma: hyper-parameter for boundary \n",
        "    # Jabocian: Jacobian vector (gradient of divergence (or loss function))\n",
        "    # dim: layer dimension \n",
        "    \n",
        "    Jacobian = tf.reshape(Jacobian, [-1, dim])\n",
        "    \n",
        "    # create current dropout mask based on keep_prob\n",
        "    mask = tf.ones_like(x)\n",
        "    mask = Dropout(mask, rate, is_train)\n",
        "\n",
        "    # mask = 0 --> -1 \n",
        "    mask = 2 * mask - tf.ones_like(mask)\n",
        "\n",
        "    adv_mask = mask \n",
        "\n",
        "    # extract the voxels for which the update conditions hold \n",
        "    # mask = 0 and J > 0 \n",
        "    # or\n",
        "    # mask = 1 and J < 1 \n",
        "    abs_jac = tf.abs(Jacobian)\n",
        "    temp = tf.cast(tf.greater(abs_jac, 0), tf.float32)\n",
        "    temp = 2 * temp - 1 \n",
        "    # interested in the cases when temp * mask = -1\n",
        "    ext = tf.cast(tf.less(mask, temp), tf.float32)\n",
        "\n",
        "    # keep the voxels that you want to update \n",
        "    candidates = abs_jac * ext \n",
        "    thres = tf.nn.top_k(candidates, int(dim * sigma * sigma)  + 1)[0][:,-1]\n",
        "\n",
        "    targets = tf.cast(tf.greater(candidates, tf.expand_dims(thres, -1)), tf.float32)\n",
        "\n",
        "    # get new mask \n",
        "    adv_mask = (mask - targets * 2 * mask + tf.ones_like(mask)) / 2.0\n",
        "\n",
        "    output = adv_mask * x\n",
        "\n",
        "    return output, adv_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkuyfHx7Zk8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "I-o9-MaZ7RxM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "''' Preprocesses the data '''\n",
        "def preprocess(data):\n",
        "    # Mean normalization\n",
        "    data = (data - 127.5) / 255.\n",
        "    # Find principal component\n",
        "    shape = data.shape\n",
        "    data = data.transpose(0, 2, 3, 1)\n",
        "    flatx = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2] * data.shape[3]))\n",
        "    sigma = np.dot(flatx.T, flatx) / flatx.shape[1]\n",
        "    U, S, V = np.linalg.svd(sigma)\n",
        "    pc = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 0.0001))), U.T)\n",
        "    # Apply ZCA whitening\n",
        "    whitex = np.dot(flatx, pc)\n",
        "    data = np.reshape(whitex, (shape[0], shape[1], shape[2], shape[3]))\n",
        "    return data\n",
        "\n",
        "\n",
        "'''\n",
        "Returns a model without adversarial dropout\n",
        "'''\n",
        "def modelWithRandD(x, n_channels=3, is_train=True):\n",
        "    x = upperBlock(x, n_channels=n_channels, is_train=is_train)\n",
        "    x = lowerBlock(x, n_in=2048, n_out=10)\n",
        "    return x\n",
        "\n",
        "\n",
        "'''\n",
        "Returns a model with adversarial dropout\n",
        "'''\n",
        "def modelWithAdD(x, y, fn_loss=KLDivergenceWithLogits, n_channels=3, is_train=True):\n",
        "    x = upperBlock(x, n_channels=n_channels, is_train=is_train)\n",
        "    y_no_adD = lowerBlock(x)\n",
        "    loss_no_adD = fn_loss(y_no_adD, y)\n",
        "\n",
        "    # Derivative of loss fn wrt x\n",
        "    DLoss = tf.gradients(loss_no_adD, [x])\n",
        "    DLoss = tf.squeeze(tf.stop_gradient(DLoss)) # Stops backpropagation\n",
        "\n",
        "    Jacobian_approx = DLoss * x\n",
        "    mask = tf.ones_like(x)\n",
        "\n",
        "    x, _ = advDropout(x, Jacobian_approx, rate=0.5, is_train=is_train)\n",
        "    x = lowerBlock(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def CreateBaseModel(x, y, learning_rate=0.001, optimizer=tf.train.AdamOptimizer, n_channels=3, is_train=True):\n",
        "    logit_rand = modelWithRandD(x, n_channels=n_channels)\n",
        "    loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "    opt = optimizer(learning_rate=learning_rate)\n",
        "    gradients = opt.compute_gradients(loss, tf.trainable_variables())\n",
        "    train_op = opt.apply_gradients(gradients)\n",
        "\n",
        "    return train_op, loss, logit_rand\n",
        "\n",
        "\n",
        "'''\n",
        "Create the AdD model for training\n",
        "'''\n",
        "def CreateAdDModel(x, y, learning_rate=0.001, optimizer=tf.train.AdamOptimizer, lmb=0.01, n_channels=3, is_train=True):\n",
        "    logit_rand = modelWithRandD(x, n_channels=n_channels, is_train=is_train)\n",
        "    logit_rand_loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
        "        # With adversarial dropout\n",
        "        logit_adD = modelWithAdD(x, y, n_channels=n_channels, is_train=is_train)\n",
        "        logit_adD_loss = CrossEntropyWithLogits(logit_adD, y)\n",
        "\n",
        "        # Total loss\n",
        "        loss = logit_rand_loss + lmb * logit_adD_loss\n",
        "\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        opt = optimizer(learning_rate=learning_rate)\n",
        "        gradients = opt.compute_gradients(loss, tf.trainable_variables())\n",
        "        train_op = opt.apply_gradients(gradients)        \n",
        "\n",
        "    return train_op, loss, logit_rand\n",
        "\n",
        "\n",
        "def CreateTestModel(x, y, n_channels=3, is_train=True):  \n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
        "        logit_rand = modelWithRandD(x, n_channels=n_channels, is_train=is_train)\n",
        "        logit_rand_loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "        return logit_rand_loss, logit_rand\n",
        "\n",
        "\n",
        "def Accuracy(logits, labels):\n",
        "    y_pred = tf.argmax(logits, 1)\n",
        "    y_true = tf.argmax(labels, 1)\n",
        "    equality = tf.equal(y_pred, y_true)\n",
        "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
        "    return accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itE0hw-RyRte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Visualization functions"
      ]
    },
    {
      "metadata": {
        "id": "EqYhVsaCyRFO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Uncomment to download graphs from google colab\n",
        "'''\n",
        "from google.colab import files\n",
        "\n",
        "def visualize(trend, param):\n",
        "    name = \"Baseline\" if param['BASELINE'] else \"Adversarial\"\n",
        "    \n",
        "    for key, val in trend.items():\n",
        "        # X axis\n",
        "        x = np.arange(len(val))\n",
        "        # Acc or loss\n",
        "        title = re.sub(\"_\", \" \", key).capitalize()\n",
        "        plt.title(title + \" \" + name)\n",
        "        plt.plot(x, val)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy' if 'acc' in key else 'Loss')\n",
        "        filename = str(key + re.sub(\"{|}|:|'|,| \", \"\", str(param)) + \".png\")\n",
        "        print(filename)\n",
        "        plt.savefig(filename)\n",
        "        files.download(filename)\n",
        "        plt.close()\n",
        "        \n",
        "        \n",
        "def visualize_both(trend_base, trend_adv, param_base, param_adv):\n",
        "    for key in trend_base.keys():\n",
        "        # X axis\n",
        "        x = np.arange(len(trend_base[key]))\n",
        "        # Acc or loss\n",
        "        title = re.sub(\"_\", \" \", key).capitalize()\n",
        "        plt.title(title)\n",
        "        plt.plot(x, trend_base[key], label='Base')\n",
        "        plt.plot(x, trend_adv[key], label='Adversarial')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy' if 'acc' in key else 'Loss')\n",
        "        plt.legend()\n",
        "        filename = str(key + '_both' + \".png\")\n",
        "        print(filename)\n",
        "        plt.savefig(filename)\n",
        "        files.download(filename)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vR2NxY1yYX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creates the graph with input/output nodes for training"
      ]
    },
    {
      "metadata": {
        "id": "nR_HLMEnaO1Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepareTrainingModel(param):\n",
        "    \n",
        "    n_channels = param['CHANNELS']\n",
        "    \n",
        "    with tf.variable_scope('Baseline' if param['BASELINE'] else 'Adversarial'):\n",
        "        # Graph\n",
        "        x_train_ph = tf.placeholder(tf.float32)\n",
        "        x_test_ph = tf.placeholder(tf.float32)\n",
        "        y_train_ph = tf.placeholder(tf.float32)\n",
        "        y_test_ph = tf.placeholder(tf.float32)\n",
        "\n",
        "        train_op, train_loss, train_logit = CreateBaseModel(x_train_ph, y_train_ph, n_channels=n_channels, is_train=True) if param['BASELINE'] else CreateAdDModel(\n",
        "            x_train_ph, y_train_ph, n_channels=n_channels, is_train=True)\n",
        "        test_loss, test_logit = CreateTestModel(x_test_ph, y_test_ph, n_channels=n_channels, is_train=False)\n",
        "\n",
        "        # Accuracy Train\n",
        "        train_accuracy = Accuracy(train_logit, y_train_ph)\n",
        "\n",
        "        # Accuracy Test\n",
        "        test_accuracy = Accuracy(test_logit, y_test_ph)  \n",
        "    \n",
        "    nodes = {\n",
        "        'x_train_ph': x_train_ph,\n",
        "        'x_test_ph': x_test_ph,\n",
        "        'y_train_ph': y_train_ph,\n",
        "        'y_test_ph': y_test_ph,\n",
        "        'train_op': train_op,\n",
        "        'train_loss': train_loss,\n",
        "        'train_logit': train_logit,\n",
        "        'test_logit': test_logit,\n",
        "        'test_loss': test_loss,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy,\n",
        "    }\n",
        "    \n",
        "    return nodes\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTfJBUiNyd9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Can perform training incrementally i.e. you do not need to run all epochs at once"
      ]
    },
    {
      "metadata": {
        "id": "ZttTkRv57Uc2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def doTraining(x_train, y_train, x_test, y_test, sess, nodes, param, trend, n_epochs=None):\n",
        "    # Training setup\n",
        "\n",
        "    batch_size = param['BATCH_SIZE']\n",
        "    epochs = param['EPOCHS'] if n_epochs is None else n_epochs\n",
        "    n_channels = x_train.shape[-1]\n",
        "\n",
        "    STEPS = len(x_train) // batch_size if param['STEPS'] is None else param['STEPS']\n",
        "    TEST_STEPS = len(x_test) // batch_size if param['STEPS'] is None else param['STEPS']\n",
        "     \n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        # Train model\n",
        "        acc_train, loss_train = 0, 0\n",
        "        for i in range(STEPS):\n",
        "            _, loss_, acc = sess.run([nodes['train_op'], nodes['train_loss'], nodes['train_accuracy']],\n",
        "                                     feed_dict={nodes['x_train_ph']: x_train[batch_size * i: batch_size * (i + 1)],\n",
        "                                                nodes['y_train_ph']: y_train[batch_size * i: batch_size * (i + 1)]})\n",
        "            acc_train += acc\n",
        "            loss_train += loss_\n",
        "\n",
        "        trend['acc_train_trend'].append(acc_train / STEPS)\n",
        "        trend['loss_train_trend'].append(loss_train / STEPS)\n",
        "\n",
        "        # Test model\n",
        "        acc_test, loss_test = 0, 0\n",
        "        for i in range(TEST_STEPS):\n",
        "            loss_t, acc_t = sess.run([nodes['test_loss'], nodes['test_accuracy']],\n",
        "                                     feed_dict={nodes['x_test_ph']: x_test[batch_size * i: batch_size * (i + 1)],\n",
        "                                                nodes['y_test_ph']: y_test[batch_size * i: batch_size * (i + 1)]})\n",
        "            acc_test += acc_t\n",
        "            loss_test += loss_t\n",
        "\n",
        "        trend['acc_test_trend'].append(acc_test / TEST_STEPS)\n",
        "        trend['loss_test_trend'].append(loss_test / TEST_STEPS)\n",
        "\n",
        "        print('Epoch: {} || Train Loss: {}, Train Acc: {} || Test Loss: {}, Test Accuracy: {}'.format(epoch,\n",
        "                                                                                                      loss_train / STEPS,\n",
        "                                                                                                      acc_train / STEPS,\n",
        "                                                                                                      loss_test / TEST_STEPS,\n",
        "                                                                                                      acc_test / TEST_STEPS))\n",
        "                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lchJVuU-yuue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data I/O and preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "gQ-V2jEK3azu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADRvrDx8iNZ0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = np.expand_dims(x_train, axis = -1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWM6pXCr3gyy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# with tf.Session() as sess:\n",
        "#     x_train = sess.run(tf.image.rgb_to_grayscale(x_train)) / 255\n",
        "#     x_test = sess.run(tf.image.rgb_to_grayscale(x_test)) / 255\n",
        "x_train, x_test = preprocess(x_train), preprocess(x_test)\n",
        "    \n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHxeKmTxe8Ni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adversarial Dropout training"
      ]
    },
    {
      "metadata": {
        "id": "klD2_w9w7yS4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "param_adv = {\n",
        "    'CHANNELS': 1,\n",
        "    'BATCH_SIZE': 128,\n",
        "    'EPOCHS': 100,\n",
        "    'STEPS': None,\n",
        "    'BASELINE': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inJ-I4gQjY-N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Run this to delete default graph w/o having to restart notebook\n",
        "'''\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKr9xYdbe5nq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nodes_adv = prepareTrainingModel(param_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALKRJKi5fHN6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trend_adv = {\n",
        "    'acc_train_trend': [],\n",
        "    'loss_train_trend': [],\n",
        "    'acc_test_trend': [],\n",
        "    'loss_test_trend': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnQ7IlKvrvp3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess_adv = tf.Session()\n",
        "sess_adv.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSm4U-yJ1dQs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1643
        },
        "outputId": "392736fa-e4d9-4569-ab95-5a5abbb1b13f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524009127302,
          "user_tz": 240,
          "elapsed": 4672945,
          "user": {
            "displayName": "Tiffany Wang",
            "photoUrl": "//lh3.googleusercontent.com/-DxivnaZLcsI/AAAAAAAAAAI/AAAAAAAAH_I/QDov37LUsKk/s50-c-k-no/photo.jpg",
            "userId": "108532619344838745606"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_adv, nodes_adv, param_adv, trend_adv, n_epochs=100)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 0.07901746204518913, Train Acc: 0.9760950854700855 || Test Loss: 0.1510687994484145, Test Accuracy: 0.9574318910256411\n",
            "Epoch: 1 || Train Loss: 0.07408480551621169, Train Acc: 0.9776308760683761 || Test Loss: 0.18343957956546011, Test Accuracy: 0.946113782051282\n",
            "Epoch: 2 || Train Loss: 0.0747570727347858, Train Acc: 0.9772636217948718 || Test Loss: 0.23171991319992605, Test Accuracy: 0.9341947115384616\n",
            "Epoch: 3 || Train Loss: 0.06827763318328951, Train Acc: 0.9788828792735043 || Test Loss: 0.21476946090562984, Test Accuracy: 0.9375\n",
            "Epoch: 4 || Train Loss: 0.06716755691025969, Train Acc: 0.9799679487179487 || Test Loss: 0.16741245377283448, Test Accuracy: 0.9542267628205128\n",
            "Epoch: 5 || Train Loss: 0.0646234484967521, Train Acc: 0.9806523771367521 || Test Loss: 0.14784404564087686, Test Accuracy: 0.9605368589743589\n",
            "Epoch: 6 || Train Loss: 0.0620915819382102, Train Acc: 0.9807024572649573 || Test Loss: 0.1487966660866872, Test Accuracy: 0.9596354166666666\n",
            "Epoch: 7 || Train Loss: 0.05793646737310287, Train Acc: 0.9819711538461539 || Test Loss: 0.14017299376428127, Test Accuracy: 0.9619391025641025\n",
            "Epoch: 8 || Train Loss: 0.05859717098388097, Train Acc: 0.9816706730769231 || Test Loss: 0.24197308600653344, Test Accuracy: 0.9394030448717948\n",
            "Epoch: 9 || Train Loss: 0.05657909318094433, Train Acc: 0.9831730769230769 || Test Loss: 0.19715982030790585, Test Accuracy: 0.9485176282051282\n",
            "Epoch: 10 || Train Loss: 0.052369628418993175, Train Acc: 0.9840578258547008 || Test Loss: 0.19839130060221905, Test Accuracy: 0.9462139423076923\n",
            "Epoch: 11 || Train Loss: 0.05264051425699583, Train Acc: 0.983840811965812 || Test Loss: 0.1969707194918719, Test Accuracy: 0.9496193910256411\n",
            "Epoch: 12 || Train Loss: 0.052103260415544014, Train Acc: 0.9839409722222222 || Test Loss: 0.1679267843779272, Test Accuracy: 0.9565304487179487\n",
            "Epoch: 13 || Train Loss: 0.04924206799913584, Train Acc: 0.9852597489316239 || Test Loss: 0.14893337799152598, Test Accuracy: 0.9633413461538461\n",
            "Epoch: 14 || Train Loss: 0.04752851408930161, Train Acc: 0.9857104700854701 || Test Loss: 0.2616996814747556, Test Accuracy: 0.9324919871794872\n",
            "Epoch: 15 || Train Loss: 0.046743696597409755, Train Acc: 0.9853599091880342 || Test Loss: 0.18802645825780928, Test Accuracy: 0.9530248397435898\n",
            "Epoch: 16 || Train Loss: 0.04668413304071326, Train Acc: 0.985793936965812 || Test Loss: 0.11945804551494522, Test Accuracy: 0.9698517628205128\n",
            "Epoch: 17 || Train Loss: 0.04430928598240149, Train Acc: 0.9867788461538461 || Test Loss: 0.22225928547469756, Test Accuracy: 0.9481169871794872\n",
            "Epoch: 18 || Train Loss: 0.04185635879498749, Train Acc: 0.9871461004273504 || Test Loss: 0.16012301163162845, Test Accuracy: 0.9616386217948718\n",
            "Epoch: 19 || Train Loss: 0.04340712164462003, Train Acc: 0.9868289262820513 || Test Loss: 0.1262395267168848, Test Accuracy: 0.9685496794871795\n",
            "Epoch: 20 || Train Loss: 0.04083259315442634, Train Acc: 0.9874298878205128 || Test Loss: 0.16175746595828783, Test Accuracy: 0.9628405448717948\n",
            "Epoch: 21 || Train Loss: 0.04063809123374054, Train Acc: 0.9874632745726496 || Test Loss: 0.16135484790757823, Test Accuracy: 0.9632411858974359\n",
            "Epoch: 22 || Train Loss: 0.04046166275066232, Train Acc: 0.9877804487179487 || Test Loss: 0.12149042398698676, Test Accuracy: 0.9696514423076923\n",
            "Epoch: 23 || Train Loss: 0.03941204104505123, Train Acc: 0.9879640758547008 || Test Loss: 0.13443212502021104, Test Accuracy: 0.9668469551282052\n",
            "Epoch: 24 || Train Loss: 0.04145653132869701, Train Acc: 0.9875133547008547 || Test Loss: 0.11123171232173217, Test Accuracy: 0.97265625\n",
            "Epoch: 25 || Train Loss: 0.038959604815831064, Train Acc: 0.9878639155982906 || Test Loss: 0.15736800440563223, Test Accuracy: 0.9621394230769231\n",
            "Epoch: 26 || Train Loss: 0.0377935493667411, Train Acc: 0.9890658386752137 || Test Loss: 0.13524294848321006, Test Accuracy: 0.9633413461538461\n",
            "Epoch: 27 || Train Loss: 0.03645952695455307, Train Acc: 0.9884648771367521 || Test Loss: 0.1310029178007076, Test Accuracy: 0.9667467948717948\n",
            "Epoch: 28 || Train Loss: 0.03762225147492688, Train Acc: 0.9884648771367521 || Test Loss: 0.1937117981037889, Test Accuracy: 0.9552283653846154\n",
            "Epoch: 29 || Train Loss: 0.03451407465430919, Train Acc: 0.9894163995726496 || Test Loss: 0.09499986540938082, Test Accuracy: 0.9760616987179487\n",
            "Epoch: 30 || Train Loss: 0.034061330376543915, Train Acc: 0.9894497863247863 || Test Loss: 0.1298558222091136, Test Accuracy: 0.9673477564102564\n",
            "Epoch: 31 || Train Loss: 0.03629415929993454, Train Acc: 0.9887486645299145 || Test Loss: 0.19112739140296187, Test Accuracy: 0.9555288461538461\n",
            "Epoch: 32 || Train Loss: 0.03441940207027758, Train Acc: 0.9893663194444444 || Test Loss: 0.1520632483498514, Test Accuracy: 0.9631410256410257\n",
            "Epoch: 33 || Train Loss: 0.03366687848746839, Train Acc: 0.9894497863247863 || Test Loss: 0.10598451251504369, Test Accuracy: 0.9749599358974359\n",
            "Epoch: 34 || Train Loss: 0.03163327483562326, Train Acc: 0.9901175213675214 || Test Loss: 0.11739368037654994, Test Accuracy: 0.9704527243589743\n",
            "Epoch: 35 || Train Loss: 0.03170076996712641, Train Acc: 0.9901676014957265 || Test Loss: 0.13786953014399236, Test Accuracy: 0.9696514423076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 || Train Loss: 0.03143161571429857, Train Acc: 0.9903679220085471 || Test Loss: 0.10832697785390803, Test Accuracy: 0.9714543269230769\n",
            "Epoch: 37 || Train Loss: 0.03302410794917044, Train Acc: 0.9896167200854701 || Test Loss: 0.2012242215972107, Test Accuracy: 0.9516225961538461\n",
            "Epoch: 38 || Train Loss: 0.03317039838290458, Train Acc: 0.9897669604700855 || Test Loss: 0.15457845292089936, Test Accuracy: 0.9636418269230769\n",
            "Epoch: 39 || Train Loss: 0.03162877863667388, Train Acc: 0.9905348557692307 || Test Loss: 0.10286386542952058, Test Accuracy: 0.9747596153846154\n",
            "Epoch: 40 || Train Loss: 0.031761798131507625, Train Acc: 0.9904013087606838 || Test Loss: 0.14700223217592934, Test Accuracy: 0.9672475961538461\n",
            "Epoch: 41 || Train Loss: 0.03262013307278169, Train Acc: 0.9899338942307693 || Test Loss: 0.14667429778581628, Test Accuracy: 0.9671474358974359\n",
            "Epoch: 42 || Train Loss: 0.031400835435150896, Train Acc: 0.9907518696581197 || Test Loss: 0.11720286465704423, Test Accuracy: 0.9712540064102564\n",
            "Epoch: 43 || Train Loss: 0.030332910269100823, Train Acc: 0.9907852564102564 || Test Loss: 0.13200669907308063, Test Accuracy: 0.971854967948718\n",
            "Epoch: 44 || Train Loss: 0.030103758341050335, Train Acc: 0.9906517094017094 || Test Loss: 0.14333562334687508, Test Accuracy: 0.9678485576923077\n",
            "Epoch: 45 || Train Loss: 0.030538021321480587, Train Acc: 0.9906183226495726 || Test Loss: 0.11973350603343882, Test Accuracy: 0.9724559294871795\n",
            "Epoch: 46 || Train Loss: 0.027386591991158546, Train Acc: 0.9920038728632479 || Test Loss: 0.14693726702870874, Test Accuracy: 0.9697516025641025\n",
            "Epoch: 47 || Train Loss: 0.029872500058437664, Train Acc: 0.9908353365384616 || Test Loss: 0.1344547695435512, Test Accuracy: 0.9708533653846154\n",
            "Epoch: 48 || Train Loss: 0.02847784042798718, Train Acc: 0.9909021100427351 || Test Loss: 0.08932761110144127, Test Accuracy: 0.9781650641025641\n",
            "Epoch: 49 || Train Loss: 0.027993703778753487, Train Acc: 0.9915531517094017 || Test Loss: 0.11560441322030666, Test Accuracy: 0.9728565705128205\n",
            "Epoch: 50 || Train Loss: 0.02635834194709468, Train Acc: 0.9917701655982906 || Test Loss: 0.09739079002443199, Test Accuracy: 0.9750600961538461\n",
            "Epoch: 51 || Train Loss: 0.027623042375234635, Train Acc: 0.9919370993589743 || Test Loss: 0.12759643820381592, Test Accuracy: 0.9698517628205128\n",
            "Epoch: 52 || Train Loss: 0.027412982649032053, Train Acc: 0.9916366185897436 || Test Loss: 0.13043441014003923, Test Accuracy: 0.9707532051282052\n",
            "Epoch: 53 || Train Loss: 0.02582486599312377, Train Acc: 0.9917033920940171 || Test Loss: 0.10063839401995303, Test Accuracy: 0.9758613782051282\n",
            "Epoch: 54 || Train Loss: 0.026910147652703234, Train Acc: 0.9917534722222222 || Test Loss: 0.12529260988678567, Test Accuracy: 0.9713541666666666\n",
            "Epoch: 55 || Train Loss: 0.031043889174764205, Train Acc: 0.9908520299145299 || Test Loss: 0.13206330308010086, Test Accuracy: 0.9682491987179487\n",
            "Epoch: 56 || Train Loss: 0.02642037089829415, Train Acc: 0.9918870192307693 || Test Loss: 0.12478161900668429, Test Accuracy: 0.9710536858974359\n",
            "Epoch: 57 || Train Loss: 0.027128655282739732, Train Acc: 0.9915698450854701 || Test Loss: 0.08081706090935115, Test Accuracy: 0.9792668269230769\n",
            "Epoch: 58 || Train Loss: 0.02702172724402927, Train Acc: 0.9917367788461539 || Test Loss: 0.11677323271653268, Test Accuracy: 0.9713541666666666\n",
            "Epoch: 59 || Train Loss: 0.026594713292598677, Train Acc: 0.9920372596153846 || Test Loss: 0.13706956855551256, Test Accuracy: 0.9670472756410257\n",
            "Epoch: 60 || Train Loss: 0.025047691251871645, Train Acc: 0.9926048344017094 || Test Loss: 0.10696707640351796, Test Accuracy: 0.9762620192307693\n",
            "Epoch: 61 || Train Loss: 0.023660881123161635, Train Acc: 0.9927550747863247 || Test Loss: 0.12922814610311223, Test Accuracy: 0.9706530448717948\n",
            "Epoch: 62 || Train Loss: 0.023437719593189247, Train Acc: 0.9929387019230769 || Test Loss: 0.11608028884940069, Test Accuracy: 0.973457532051282\n",
            "Epoch: 63 || Train Loss: 0.026160290241955993, Train Acc: 0.9920205662393162 || Test Loss: 0.12490315346692044, Test Accuracy: 0.9717548076923077\n",
            "Epoch: 64 || Train Loss: 0.02642796102543829, Train Acc: 0.9913194444444444 || Test Loss: 0.13152131168559814, Test Accuracy: 0.96875\n",
            "Epoch: 65 || Train Loss: 0.027085320612813175, Train Acc: 0.9921207264957265 || Test Loss: 0.09381316825863159, Test Accuracy: 0.9781650641025641\n",
            "Epoch: 66 || Train Loss: 0.024343276077604222, Train Acc: 0.9925547542735043 || Test Loss: 0.11226618540240452, Test Accuracy: 0.9736578525641025\n",
            "Epoch: 67 || Train Loss: 0.025160743320903307, Train Acc: 0.9926382211538461 || Test Loss: 0.10546502723166039, Test Accuracy: 0.9741586538461539\n",
            "Epoch: 68 || Train Loss: 0.024996761372210293, Train Acc: 0.9928385416666666 || Test Loss: 0.09145108491858804, Test Accuracy: 0.9797676282051282\n",
            "Epoch: 69 || Train Loss: 0.02394636367306446, Train Acc: 0.9927049946581197 || Test Loss: 0.1397325516321498, Test Accuracy: 0.9697516025641025\n",
            "Epoch: 70 || Train Loss: 0.02309169421945797, Train Acc: 0.9928719284188035 || Test Loss: 0.11970399368893152, Test Accuracy: 0.9744591346153846\n",
            "Epoch: 71 || Train Loss: 0.02115181570765826, Train Acc: 0.993339342948718 || Test Loss: 0.1459599691640902, Test Accuracy: 0.9651442307692307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 72 || Train Loss: 0.02526475533555547, Train Acc: 0.9922876602564102 || Test Loss: 0.11274072983696197, Test Accuracy: 0.9737580128205128\n",
            "Epoch: 73 || Train Loss: 0.020495682663353457, Train Acc: 0.9933727297008547 || Test Loss: 0.12193603986219013, Test Accuracy: 0.9742588141025641\n",
            "Epoch: 74 || Train Loss: 0.023027760130216693, Train Acc: 0.9933059561965812 || Test Loss: 0.14843361799452956, Test Accuracy: 0.9674479166666666\n",
            "Epoch: 75 || Train Loss: 0.025030423978520965, Train Acc: 0.9921040331196581 || Test Loss: 0.15786012513742137, Test Accuracy: 0.965645032051282\n",
            "Epoch: 76 || Train Loss: 0.02121223973536428, Train Acc: 0.9933059561965812 || Test Loss: 0.13457506136201586, Test Accuracy: 0.9739583333333334\n",
            "Epoch: 77 || Train Loss: 0.021613190933650026, Train Acc: 0.9936565170940171 || Test Loss: 0.1606725969408543, Test Accuracy: 0.9670472756410257\n",
            "Epoch: 78 || Train Loss: 0.022070360119674955, Train Acc: 0.9931724091880342 || Test Loss: 0.13675278700285184, Test Accuracy: 0.9700520833333334\n",
            "Epoch: 79 || Train Loss: 0.02341468842768468, Train Acc: 0.9928719284188035 || Test Loss: 0.10516461543067215, Test Accuracy: 0.9763621794871795\n",
            "Epoch: 80 || Train Loss: 0.02128413221843457, Train Acc: 0.9936398237179487 || Test Loss: 0.11466171050881549, Test Accuracy: 0.9748597756410257\n",
            "Epoch: 81 || Train Loss: 0.019367151038563745, Train Acc: 0.9939236111111112 || Test Loss: 0.11419411935574504, Test Accuracy: 0.9752604166666666\n",
            "Epoch: 82 || Train Loss: 0.02172978855797644, Train Acc: 0.9932224893162394 || Test Loss: 0.08868607464998417, Test Accuracy: 0.9810697115384616\n",
            "Epoch: 83 || Train Loss: 0.020835846502294825, Train Acc: 0.9930722489316239 || Test Loss: 0.11495411272298019, Test Accuracy: 0.9758613782051282\n",
            "Epoch: 84 || Train Loss: 0.021754193354206662, Train Acc: 0.9931056356837606 || Test Loss: 0.16857187584294783, Test Accuracy: 0.9652443910256411\n",
            "Epoch: 85 || Train Loss: 0.0231677124783167, Train Acc: 0.9930722489316239 || Test Loss: 0.12657908769576282, Test Accuracy: 0.9732572115384616\n",
            "Epoch: 86 || Train Loss: 0.02213262993977509, Train Acc: 0.9934228098290598 || Test Loss: 0.12099469819039745, Test Accuracy: 0.9748597756410257\n",
            "Epoch: 87 || Train Loss: 0.02303811335015127, Train Acc: 0.9931891025641025 || Test Loss: 0.14157761224711207, Test Accuracy: 0.9702524038461539\n",
            "Epoch: 88 || Train Loss: 0.021383766950515193, Train Acc: 0.9934228098290598 || Test Loss: 0.11357096694677565, Test Accuracy: 0.9784655448717948\n",
            "Epoch: 89 || Train Loss: 0.02215737026261537, Train Acc: 0.9930388621794872 || Test Loss: 0.13043288777109224, Test Accuracy: 0.9727564102564102\n",
            "Epoch: 90 || Train Loss: 0.022795647053639047, Train Acc: 0.9931390224358975 || Test Loss: 0.15907504773125625, Test Accuracy: 0.9673477564102564\n",
            "Epoch: 91 || Train Loss: 0.023348419377072833, Train Acc: 0.9928552350427351 || Test Loss: 0.12306903822247524, Test Accuracy: 0.9747596153846154\n",
            "Epoch: 92 || Train Loss: 0.0200375331765811, Train Acc: 0.9940738514957265 || Test Loss: 0.1105217610907764, Test Accuracy: 0.9777644230769231\n",
            "Epoch: 93 || Train Loss: 0.02233924636695333, Train Acc: 0.9927884615384616 || Test Loss: 0.08562842436181083, Test Accuracy: 0.9828725961538461\n",
            "Epoch: 94 || Train Loss: 0.02153182683870023, Train Acc: 0.9935730502136753 || Test Loss: 0.10849428554287535, Test Accuracy: 0.9774639423076923\n",
            "Epoch: 95 || Train Loss: 0.020320664136209563, Train Acc: 0.9937733707264957 || Test Loss: 0.10647064266063702, Test Accuracy: 0.9769631410256411\n",
            "Epoch: 96 || Train Loss: 0.02086816935938508, Train Acc: 0.9938234508547008 || Test Loss: 0.14782661474414338, Test Accuracy: 0.9678485576923077\n",
            "Epoch: 97 || Train Loss: 0.021303149654944033, Train Acc: 0.993606436965812 || Test Loss: 0.10061598988030686, Test Accuracy: 0.9809695512820513\n",
            "Epoch: 98 || Train Loss: 0.020528049998753507, Train Acc: 0.9938234508547008 || Test Loss: 0.09524405278352788, Test Accuracy: 0.9816706730769231\n",
            "Epoch: 99 || Train Loss: 0.021539086991935588, Train Acc: 0.9933226495726496 || Test Loss: 0.13325782766817915, Test Accuracy: 0.969551282051282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MOTkA8amjDQy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('adv_trend.json', 'w') as fp:\n",
        "    json.dump(trend_adv, fp)\n",
        "files.download('adv_trend.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlfkuFMHXpFn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9be5fcee-c4c3-4c52-fa9a-58020ad6f1b7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523937748921,
          "user_tz": 240,
          "elapsed": 2466,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize(trend_adv, param_adv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "loss_train_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "acc_test_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "loss_test_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXLHPa13bsP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline Training"
      ]
    },
    {
      "metadata": {
        "id": "VaJHqe25bud3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "param_base = {\n",
        "    'CHANNELS': 1,\n",
        "    'BATCH_SIZE': 128,\n",
        "    'EPOCHS': 100,\n",
        "    'STEPS': None,\n",
        "    'BASELINE': True\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_1a-gb_byBP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nodes_base = prepareTrainingModel(param_base)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "390LlVp2b2gI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trend_base = {\n",
        "    'acc_train_trend': [],\n",
        "    'loss_train_trend': [],\n",
        "    'acc_test_trend': [],\n",
        "    'loss_test_trend': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vrlfTDnab6WI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess_base = tf.Session()\n",
        "sess_base.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbHu1L1pc3-O",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1643
        },
        "outputId": "f62dbbb9-ddbe-422b-a436-6465a3e8002d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524010675135,
          "user_tz": 240,
          "elapsed": 1516213,
          "user": {
            "displayName": "Tiffany Wang",
            "photoUrl": "//lh3.googleusercontent.com/-DxivnaZLcsI/AAAAAAAAAAI/AAAAAAAAH_I/QDov37LUsKk/s50-c-k-no/photo.jpg",
            "userId": "108532619344838745606"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_base, nodes_base, param_base, trend_base, n_epochs=100)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 1.1412763578387408, Train Acc: 0.7677450587606838 || Test Loss: 6.350931124809461, Test Accuracy: 0.3345352564102564\n",
            "Epoch: 1 || Train Loss: 0.33705859178772724, Train Acc: 0.9027276976495726 || Test Loss: 3.8171186324877615, Test Accuracy: 0.5291466346153846\n",
            "Epoch: 2 || Train Loss: 0.2247361671179533, Train Acc: 0.9337606837606838 || Test Loss: 2.338742897296563, Test Accuracy: 0.6642628205128205\n",
            "Epoch: 3 || Train Loss: 0.16878235779511622, Train Acc: 0.9485343215811965 || Test Loss: 1.8510233438931978, Test Accuracy: 0.7350761217948718\n",
            "Epoch: 4 || Train Loss: 0.1460261662594146, Train Acc: 0.9558460202991453 || Test Loss: 0.6555017599692712, Test Accuracy: 0.8719951923076923\n",
            "Epoch: 5 || Train Loss: 0.12228317553591397, Train Acc: 0.9630408653846154 || Test Loss: 0.7106628169616064, Test Accuracy: 0.8548677884615384\n",
            "Epoch: 6 || Train Loss: 0.10874114975802855, Train Acc: 0.9668302617521367 || Test Loss: 0.2658417300703243, Test Accuracy: 0.9470152243589743\n",
            "Epoch: 7 || Train Loss: 0.09973575529278232, Train Acc: 0.9694177350427351 || Test Loss: 0.4439707082242538, Test Accuracy: 0.9165665064102564\n",
            "Epoch: 8 || Train Loss: 0.09073327370903367, Train Acc: 0.9724225427350427 || Test Loss: 0.37105861546185154, Test Accuracy: 0.9263822115384616\n",
            "Epoch: 9 || Train Loss: 0.08246189128591591, Train Acc: 0.9750100160256411 || Test Loss: 0.4020524717007692, Test Accuracy: 0.9246794871794872\n",
            "Epoch: 10 || Train Loss: 0.07953481140629086, Train Acc: 0.9753104967948718 || Test Loss: 0.30305682260017747, Test Accuracy: 0.9468149038461539\n",
            "Epoch: 11 || Train Loss: 0.07748204686491886, Train Acc: 0.9765291132478633 || Test Loss: 0.23220076108984172, Test Accuracy: 0.961738782051282\n",
            "Epoch: 12 || Train Loss: 0.07345486707233179, Train Acc: 0.9770799946581197 || Test Loss: 0.2563460500230296, Test Accuracy: 0.9547275641025641\n",
            "Epoch: 13 || Train Loss: 0.06540931871747419, Train Acc: 0.9800347222222222 || Test Loss: 0.2505127689263855, Test Accuracy: 0.9574318910256411\n",
            "Epoch: 14 || Train Loss: 0.06229909163389532, Train Acc: 0.9799178685897436 || Test Loss: 0.2489205108722672, Test Accuracy: 0.9586338141025641\n",
            "Epoch: 15 || Train Loss: 0.0646198184533407, Train Acc: 0.9799512553418803 || Test Loss: 0.24932129389922827, Test Accuracy: 0.9632411858974359\n",
            "Epoch: 16 || Train Loss: 0.06127145770801884, Train Acc: 0.981270032051282 || Test Loss: 0.33149875811217594, Test Accuracy: 0.9475160256410257\n",
            "Epoch: 17 || Train Loss: 0.05973481696345804, Train Acc: 0.9814703525641025 || Test Loss: 0.29608440158802135, Test Accuracy: 0.9554286858974359\n",
            "Epoch: 18 || Train Loss: 0.05943550189262262, Train Acc: 0.9813868856837606 || Test Loss: 0.2493061576074419, Test Accuracy: 0.9635416666666666\n",
            "Epoch: 19 || Train Loss: 0.05217346746803353, Train Acc: 0.9839910523504274 || Test Loss: 0.24244825518876612, Test Accuracy: 0.9658453525641025\n",
            "Epoch: 20 || Train Loss: 0.05571365750823981, Train Acc: 0.9827223557692307 || Test Loss: 0.2705485793403335, Test Accuracy: 0.9630408653846154\n",
            "Epoch: 21 || Train Loss: 0.055099962772597544, Train Acc: 0.9831563835470085 || Test Loss: 0.36271951876383707, Test Accuracy: 0.9501201923076923\n",
            "Epoch: 22 || Train Loss: 0.04736713513961553, Train Acc: 0.9847923344017094 || Test Loss: 0.405631722154048, Test Accuracy: 0.942207532051282\n",
            "Epoch: 23 || Train Loss: 0.04851444047806923, Train Acc: 0.9844751602564102 || Test Loss: 0.3521346768591171, Test Accuracy: 0.9545272435897436\n",
            "Epoch: 24 || Train Loss: 0.04624466852157608, Train Acc: 0.9854767628205128 || Test Loss: 0.45452200239285445, Test Accuracy: 0.9405048076923077\n",
            "Epoch: 25 || Train Loss: 0.047372378448125946, Train Acc: 0.9858273237179487 || Test Loss: 0.27587040414054614, Test Accuracy: 0.9669471153846154\n",
            "Epoch: 26 || Train Loss: 0.04299671330081143, Train Acc: 0.9861778846153846 || Test Loss: 0.35189632916388713, Test Accuracy: 0.9545272435897436\n",
            "Epoch: 27 || Train Loss: 0.04455662625839309, Train Acc: 0.9857772435897436 || Test Loss: 0.4255385512231628, Test Accuracy: 0.9514222756410257\n",
            "Epoch: 28 || Train Loss: 0.04131714353297089, Train Acc: 0.9869958600427351 || Test Loss: 0.4227133150524575, Test Accuracy: 0.9598357371794872\n",
            "Epoch: 29 || Train Loss: 0.0406356257476118, Train Acc: 0.9870960202991453 || Test Loss: 0.42020709887275676, Test Accuracy: 0.9565304487179487\n",
            "Epoch: 30 || Train Loss: 0.04131783233506756, Train Acc: 0.9870793269230769 || Test Loss: 0.48086526325287426, Test Accuracy: 0.9456129807692307\n",
            "Epoch: 31 || Train Loss: 0.04195171212899383, Train Acc: 0.9873464209401709 || Test Loss: 0.4533896001767994, Test Accuracy: 0.9567307692307693\n",
            "Epoch: 32 || Train Loss: 0.04489135147892568, Train Acc: 0.9862112713675214 || Test Loss: 0.35859373095546776, Test Accuracy: 0.9650440705128205\n",
            "Epoch: 33 || Train Loss: 0.038926366564045856, Train Acc: 0.9877136752136753 || Test Loss: 0.48605000285048544, Test Accuracy: 0.9589342948717948\n",
            "Epoch: 34 || Train Loss: 0.03853508175296498, Train Acc: 0.9879473824786325 || Test Loss: 0.4428883190944551, Test Accuracy: 0.9620392628205128\n",
            "Epoch: 35 || Train Loss: 0.03691018840591769, Train Acc: 0.9884815705128205 || Test Loss: 0.5058542398302637, Test Accuracy: 0.9644431089743589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 || Train Loss: 0.035470650018412105, Train Acc: 0.9882979433760684 || Test Loss: 0.45416064732680983, Test Accuracy: 0.9603365384615384\n",
            "Epoch: 37 || Train Loss: 0.03798578470878444, Train Acc: 0.9884314903846154 || Test Loss: 0.5300305628248615, Test Accuracy: 0.9598357371794872\n",
            "Epoch: 38 || Train Loss: 0.03505497771281322, Train Acc: 0.9886985844017094 || Test Loss: 0.6701640195645805, Test Accuracy: 0.9559294871794872\n",
            "Epoch: 39 || Train Loss: 0.036162798986171966, Train Acc: 0.9884982638888888 || Test Loss: 0.566128050263463, Test Accuracy: 0.9589342948717948\n",
            "Epoch: 40 || Train Loss: 0.03524424920903825, Train Acc: 0.9892995459401709 || Test Loss: 1.0345396110071585, Test Accuracy: 0.9258814102564102\n",
            "Epoch: 41 || Train Loss: 0.03487873560808446, Train Acc: 0.989082532051282 || Test Loss: 0.4871325163119163, Test Accuracy: 0.9623397435897436\n",
            "Epoch: 42 || Train Loss: 0.031168693558216685, Train Acc: 0.9896167200854701 || Test Loss: 0.8645058341879541, Test Accuracy: 0.9393028846153846\n",
            "Epoch: 43 || Train Loss: 0.03215998042812635, Train Acc: 0.9894664797008547 || Test Loss: 1.0049000431437236, Test Accuracy: 0.9362980769230769\n",
            "Epoch: 44 || Train Loss: 0.0309086078880208, Train Acc: 0.9899839743589743 || Test Loss: 0.9832017997709604, Test Accuracy: 0.9369991987179487\n",
            "Epoch: 45 || Train Loss: 0.03129302044502625, Train Acc: 0.989967280982906 || Test Loss: 0.8864112684061463, Test Accuracy: 0.9462139423076923\n",
            "Epoch: 46 || Train Loss: 0.03156938494002966, Train Acc: 0.9903512286324786 || Test Loss: 0.8253878144866739, Test Accuracy: 0.9444110576923077\n",
            "Epoch: 47 || Train Loss: 0.032854029004272145, Train Acc: 0.989700186965812 || Test Loss: 1.0409497590019152, Test Accuracy: 0.9354967948717948\n",
            "Epoch: 48 || Train Loss: 0.03441268477904215, Train Acc: 0.9890157585470085 || Test Loss: 0.6865786103057179, Test Accuracy: 0.9630408653846154\n",
            "Epoch: 49 || Train Loss: 0.02985284980237867, Train Acc: 0.9908687232905983 || Test Loss: 0.8295683977851532, Test Accuracy: 0.9473157051282052\n",
            "Epoch: 50 || Train Loss: 0.03019107846108439, Train Acc: 0.9908854166666666 || Test Loss: 0.7561952587951591, Test Accuracy: 0.9517227564102564\n",
            "Epoch: 51 || Train Loss: 0.028838541907950852, Train Acc: 0.9909521901709402 || Test Loss: 1.0731469370866376, Test Accuracy: 0.9404046474358975\n",
            "Epoch: 52 || Train Loss: 0.028167379454363328, Train Acc: 0.9909688835470085 || Test Loss: 1.1046553038822122, Test Accuracy: 0.9375\n",
            "Epoch: 53 || Train Loss: 0.028878326162927036, Train Acc: 0.9908353365384616 || Test Loss: 0.9140735647560154, Test Accuracy: 0.9465144230769231\n",
            "Epoch: 54 || Train Loss: 0.02830383909678438, Train Acc: 0.9909855769230769 || Test Loss: 0.9249461989262432, Test Accuracy: 0.9516225961538461\n",
            "Epoch: 55 || Train Loss: 0.029589449229424022, Train Acc: 0.9909188034188035 || Test Loss: 1.0171008373238295, Test Accuracy: 0.9452123397435898\n",
            "Epoch: 56 || Train Loss: 0.027696219971780494, Train Acc: 0.9912359775641025 || Test Loss: 1.194292777791839, Test Accuracy: 0.9389022435897436\n",
            "Epoch: 57 || Train Loss: 0.02647244875720972, Train Acc: 0.9917534722222222 || Test Loss: 1.0395780814439621, Test Accuracy: 0.9501201923076923\n",
            "Epoch: 58 || Train Loss: 0.02826995230339563, Train Acc: 0.9909354967948718 || Test Loss: 0.7365380045774645, Test Accuracy: 0.9674479166666666\n",
            "Epoch: 59 || Train Loss: 0.02737622430015854, Train Acc: 0.9913695245726496 || Test Loss: 0.6333406313136997, Test Accuracy: 0.9732572115384616\n",
            "Epoch: 60 || Train Loss: 0.029728616013386257, Train Acc: 0.9909521901709402 || Test Loss: 0.536424789486239, Test Accuracy: 0.9732572115384616\n",
            "Epoch: 61 || Train Loss: 0.02441583354632996, Train Acc: 0.9919704861111112 || Test Loss: 0.6728695642525214, Test Accuracy: 0.9732572115384616\n",
            "Epoch: 62 || Train Loss: 0.02480211637918503, Train Acc: 0.9919704861111112 || Test Loss: 0.663015574206751, Test Accuracy: 0.9706530448717948\n",
            "Epoch: 63 || Train Loss: 0.026788702327522538, Train Acc: 0.9916032318376068 || Test Loss: 0.7402499580144138, Test Accuracy: 0.9694511217948718\n",
            "Epoch: 64 || Train Loss: 0.028372560606544733, Train Acc: 0.9914029113247863 || Test Loss: 0.858432269817143, Test Accuracy: 0.9659455128205128\n",
            "Epoch: 65 || Train Loss: 0.025784098098141778, Train Acc: 0.9916366185897436 || Test Loss: 0.923940586933116, Test Accuracy: 0.9623397435897436\n",
            "Epoch: 66 || Train Loss: 0.02618679186155291, Train Acc: 0.9914529914529915 || Test Loss: 0.8737241415887459, Test Accuracy: 0.9642427884615384\n",
            "Epoch: 67 || Train Loss: 0.025054658256335526, Train Acc: 0.9919871794871795 || Test Loss: 1.2275193936485518, Test Accuracy: 0.9520232371794872\n",
            "Epoch: 68 || Train Loss: 0.02355012149070375, Train Acc: 0.9925380608974359 || Test Loss: 1.1383815057665487, Test Accuracy: 0.9603365384615384\n",
            "Epoch: 69 || Train Loss: 0.027450808527980847, Train Acc: 0.9919037126068376 || Test Loss: 0.9312112492506828, Test Accuracy: 0.9628405448717948\n",
            "Epoch: 70 || Train Loss: 0.02674114633982443, Train Acc: 0.991920405982906 || Test Loss: 0.9447732185964676, Test Accuracy: 0.9618389423076923\n",
            "Epoch: 71 || Train Loss: 0.023084206723069656, Train Acc: 0.9926382211538461 || Test Loss: 0.8179930425905757, Test Accuracy: 0.9665464743589743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 72 || Train Loss: 0.02561755399686721, Train Acc: 0.9919370993589743 || Test Loss: 1.097620500688739, Test Accuracy: 0.9574318910256411\n",
            "Epoch: 73 || Train Loss: 0.025747363585418126, Train Acc: 0.9924045138888888 || Test Loss: 0.8118767844281859, Test Accuracy: 0.9693509615384616\n",
            "Epoch: 74 || Train Loss: 0.022993762687541226, Train Acc: 0.9926048344017094 || Test Loss: 0.8412136378046565, Test Accuracy: 0.9705528846153846\n",
            "Epoch: 75 || Train Loss: 0.024485324804550533, Train Acc: 0.9924379006410257 || Test Loss: 0.9082037869791949, Test Accuracy: 0.9678485576923077\n",
            "Epoch: 76 || Train Loss: 0.022571357291874452, Train Acc: 0.9928886217948718 || Test Loss: 1.159375392204571, Test Accuracy: 0.9581330128205128\n",
            "Epoch: 77 || Train Loss: 0.02481252411423786, Train Acc: 0.9921875 || Test Loss: 0.9447161417832924, Test Accuracy: 0.9683493589743589\n",
            "Epoch: 78 || Train Loss: 0.022281886472953382, Train Acc: 0.9926716079059829 || Test Loss: 1.1639912793890774, Test Accuracy: 0.9633413461538461\n",
            "Epoch: 79 || Train Loss: 0.02292110039500072, Train Acc: 0.9925213675213675 || Test Loss: 0.8726436170138852, Test Accuracy: 0.9738581730769231\n",
            "Epoch: 80 || Train Loss: 0.02344974438129518, Train Acc: 0.9925547542735043 || Test Loss: 1.0078916892087209, Test Accuracy: 0.9644431089743589\n",
            "Epoch: 81 || Train Loss: 0.023210036123713446, Train Acc: 0.9926382211538461 || Test Loss: 1.129150527680627, Test Accuracy: 0.9598357371794872\n",
            "Epoch: 82 || Train Loss: 0.02307574524440155, Train Acc: 0.9926382211538461 || Test Loss: 0.9800429260995167, Test Accuracy: 0.9712540064102564\n",
            "Epoch: 83 || Train Loss: 0.021489770913202387, Train Acc: 0.9931223290598291 || Test Loss: 0.9082406779387557, Test Accuracy: 0.9713541666666666\n",
            "Epoch: 84 || Train Loss: 0.02447180894249223, Train Acc: 0.9922208867521367 || Test Loss: 0.9944419434679079, Test Accuracy: 0.9702524038461539\n",
            "Epoch: 85 || Train Loss: 0.022895491816011814, Train Acc: 0.9929220085470085 || Test Loss: 0.8620060557956253, Test Accuracy: 0.9759615384615384\n",
            "Epoch: 86 || Train Loss: 0.022298527258874302, Train Acc: 0.9928051549145299 || Test Loss: 1.1580646733145186, Test Accuracy: 0.9667467948717948\n",
            "Epoch: 87 || Train Loss: 0.024508273825763625, Train Acc: 0.9923544337606838 || Test Loss: 1.1541411489036382, Test Accuracy: 0.9703525641025641\n",
            "Epoch: 88 || Train Loss: 0.020703331450504188, Train Acc: 0.9932892628205128 || Test Loss: 1.0813180074923165, Test Accuracy: 0.9715544871794872\n",
            "Epoch: 89 || Train Loss: 0.021515625035612697, Train Acc: 0.9934895833333334 || Test Loss: 1.2401083790531549, Test Accuracy: 0.9684495192307693\n",
            "Epoch: 90 || Train Loss: 0.020402315900108655, Train Acc: 0.9933727297008547 || Test Loss: 0.923686522748348, Test Accuracy: 0.9715544871794872\n",
            "Epoch: 91 || Train Loss: 0.0215283641741074, Train Acc: 0.9929553952991453 || Test Loss: 0.9003903288600241, Test Accuracy: 0.9742588141025641\n",
            "Epoch: 92 || Train Loss: 0.02123052102398595, Train Acc: 0.9935730502136753 || Test Loss: 1.0160980657979088, Test Accuracy: 0.9751602564102564\n",
            "Epoch: 93 || Train Loss: 0.021540004585662416, Train Acc: 0.9932558760683761 || Test Loss: 1.0849910578361905, Test Accuracy: 0.9724559294871795\n",
            "Epoch: 94 || Train Loss: 0.02459082947202621, Train Acc: 0.9925380608974359 || Test Loss: 1.2058940720943587, Test Accuracy: 0.9755608974358975\n",
            "Epoch: 95 || Train Loss: 0.02221357366384063, Train Acc: 0.9926549145299145 || Test Loss: 1.31838620345944, Test Accuracy: 0.9709535256410257\n",
            "Epoch: 96 || Train Loss: 0.021302774819400645, Train Acc: 0.9934061164529915 || Test Loss: 1.2606169737624267, Test Accuracy: 0.9728565705128205\n",
            "Epoch: 97 || Train Loss: 0.020577229054920165, Train Acc: 0.9932558760683761 || Test Loss: 1.7657535453252133, Test Accuracy: 0.9591346153846154\n",
            "Epoch: 98 || Train Loss: 0.022411539891187653, Train Acc: 0.9931223290598291 || Test Loss: 1.2057560301176729, Test Accuracy: 0.9758613782051282\n",
            "Epoch: 99 || Train Loss: 0.019671181133259632, Train Acc: 0.9934895833333334 || Test Loss: 1.5032474291675346, Test Accuracy: 0.9724559294871795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BuZBeP_Fc-h2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('base_trend.json', 'w') as fp:\n",
        "    json.dump(trend_base, fp)\n",
        "files.download('base_trend.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsSFXhRotGdV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "808ea3a9-79b1-405d-94aa-421c7ed9d4cb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524011337571,
          "user_tz": 240,
          "elapsed": 2541,
          "user": {
            "displayName": "Tiffany Wang",
            "photoUrl": "//lh3.googleusercontent.com/-DxivnaZLcsI/AAAAAAAAAAI/AAAAAAAAH_I/QDov37LUsKk/s50-c-k-no/photo.jpg",
            "userId": "108532619344838745606"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize(trend_base, param_base)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trendCHANNELS1BATCH_SIZE128EPOCHS100STEPSNoneBASELINETrue.png\n",
            "loss_train_trendCHANNELS1BATCH_SIZE128EPOCHS100STEPSNoneBASELINETrue.png\n",
            "acc_test_trendCHANNELS1BATCH_SIZE128EPOCHS100STEPSNoneBASELINETrue.png\n",
            "loss_test_trendCHANNELS1BATCH_SIZE128EPOCHS100STEPSNoneBASELINETrue.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ruTt4wvlOvy7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "visualize_both(trend_base, trend_adv, param_base, param_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnqffYuvzANK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trying more epochs for baseline"
      ]
    },
    {
      "metadata": {
        "id": "ep-ieptUzHAV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1c49aa61-4432-49a9-bf40-62013b2dc3b6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523939532599,
          "user_tz": 240,
          "elapsed": 1255242,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_base, nodes_base, param_base, trend_base, n_epochs=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 0.4114689419666926, Train Acc: 0.8565705128205128 || Test Loss: 2.62478596277726, Test Accuracy: 0.6821915064102564\n",
            "Epoch: 1 || Train Loss: 0.4116022842434736, Train Acc: 0.8560296474358975 || Test Loss: 2.397842292602246, Test Accuracy: 0.6944110576923077\n",
            "Epoch: 2 || Train Loss: 0.40900135078491306, Train Acc: 0.8569711538461539 || Test Loss: 2.573611721014365, Test Accuracy: 0.6738782051282052\n",
            "Epoch: 3 || Train Loss: 0.3950696151990157, Train Acc: 0.8607371794871795 || Test Loss: 2.2602377350513754, Test Accuracy: 0.7008213141025641\n",
            "Epoch: 4 || Train Loss: 0.3882401616909565, Train Acc: 0.864863782051282 || Test Loss: 2.585665913728567, Test Accuracy: 0.6643629807692307\n",
            "Epoch: 5 || Train Loss: 0.37742966432601976, Train Acc: 0.8680889423076923 || Test Loss: 2.890182140545967, Test Accuracy: 0.6627604166666666\n",
            "Epoch: 6 || Train Loss: 0.3734817562194971, Train Acc: 0.8680889423076923 || Test Loss: 3.031246014130421, Test Accuracy: 0.6494391025641025\n",
            "Epoch: 7 || Train Loss: 0.359975000566397, Train Acc: 0.8758413461538461 || Test Loss: 2.6715997625619936, Test Accuracy: 0.6796875\n",
            "Epoch: 8 || Train Loss: 0.35318817286155163, Train Acc: 0.8778245192307692 || Test Loss: 2.641043097544939, Test Accuracy: 0.6655649038461539\n",
            "Epoch: 9 || Train Loss: 0.36321620106315, Train Acc: 0.875 || Test Loss: 2.507852470263457, Test Accuracy: 0.6934094551282052\n",
            "Epoch: 10 || Train Loss: 0.3420440094211163, Train Acc: 0.8801282051282051 || Test Loss: 2.940065249418601, Test Accuracy: 0.6860977564102564\n",
            "Epoch: 11 || Train Loss: 0.3411940868466328, Train Acc: 0.8813100961538461 || Test Loss: 2.460312461241698, Test Accuracy: 0.6845953525641025\n",
            "Epoch: 12 || Train Loss: 0.3514612724765753, Train Acc: 0.8767027243589743 || Test Loss: 2.970283636680016, Test Accuracy: 0.6717748397435898\n",
            "Epoch: 13 || Train Loss: 0.33671844261579026, Train Acc: 0.8831330128205128 || Test Loss: 3.029020295693324, Test Accuracy: 0.6650641025641025\n",
            "Epoch: 14 || Train Loss: 0.3231771155427664, Train Acc: 0.8869591346153847 || Test Loss: 3.4224790120736146, Test Accuracy: 0.6385216346153846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f-NqSc4GzLez",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}