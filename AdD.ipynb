{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdD.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UdoHEU7TZM3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adversarial Dropout Code\n",
        "#### This file contains the code used to replicate the results of Adversarial Dropout"
      ]
    },
    {
      "metadata": {
        "id": "yNPBWy4_vAu3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d0G1RJtjY5gx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "4WzEOO-77L24",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 123456\n",
        "rng = np.random.RandomState(SEED)\n",
        "\n",
        "\n",
        "def __createWeights(shape, seed=None, name='weight'):\n",
        "    w_init = tf.contrib.layers.variance_scaling_initializer(seed=seed)\n",
        "    return tf.get_variable(name + '_w', shape=shape, initializer=w_init)\n",
        "    \n",
        "\n",
        "def __createBiases(size, name='bias'):\n",
        "    return tf.get_variable(name + '_b', shape=[size], initializer=tf.constant_initializer(0.0))\n",
        "\n",
        "\n",
        "def LeakyReLU(x, alpha=0.1):\n",
        "    x = tf.nn.leaky_relu(x, alpha=alpha)\n",
        "    return x\n",
        "\n",
        "\n",
        "def MaxPooling(x, ksize=2, stride_length=2, padding='SAME', data_format='NHWC'):\n",
        "    x = tf.nn.max_pool(x, (1, ksize, ksize, 1), (1, stride_length, stride_length, 1), padding, data_format)\n",
        "    return x\n",
        "\n",
        "\n",
        "def GlobalAveragePooling(x):\n",
        "    x = tf.reduce_mean(x, [1, 2])\n",
        "    return x\n",
        "\n",
        "\n",
        "def Dense(x, input_dim, output_dim, seed=None, name='dense'):\n",
        "    W = __createWeights([input_dim, output_dim], seed, name) \n",
        "    b = __createBiases(output_dim, name) \n",
        "    x = tf.nn.xw_plus_b(x, W, b)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Conv2D(x, filter_size, n_channels, n_filters, stride_length=1, padding='SAME', data_format='NHWC', name='conv'):\n",
        "    shape = [filter_size, filter_size, n_channels, n_filters]\n",
        "    W = __createWeights(shape, name=name)\n",
        "    b = __createBiases(n_filters, name=name)\n",
        "    x = tf.nn.conv2d(x, filter=W, strides=(1, stride_length, stride_length, 1), padding=padding, data_format=data_format)\n",
        "    x += b\n",
        "    return x\n",
        "\n",
        "\n",
        "def Dropout(x, rate=0.5, is_train=True):\n",
        "    x = tf.layers.dropout(x, rate=rate, seed=rng.randint(SEED), training=is_train)\n",
        "    return x\n",
        "\n",
        "\n",
        "def GaussianNoise(x, sigma=0.15):\n",
        "    noise = tf.random_normal(shape=tf.shape(x), stddev=sigma)\n",
        "    x += noise\n",
        "    return x\n",
        "\n",
        "\n",
        "def SoftMax(x):\n",
        "    x = tf.nn.softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='bn'):\n",
        "    x = tf.layers.batch_normalization(x, axis=axis, training=is_train, momentum=momentum, name=name)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Loss functions. Arg 1: Approximation, Arg 2: Labels\n",
        "'''\n",
        "def CrossEntropyWithLogits(logits, labels):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Formula: sum(p_i * log(p_i) - p_i * log(q_i))\n",
        "def KLDivergenceWithLogits(q, p):\n",
        "    p_soft = SoftMax(p)\n",
        "    # plogp = tf.reduce_mean(tf.reduce_sum(p_soft * tf.nn.log_softmax(p), 1))\n",
        "    # plogq = tf.reduce_mean(tf.reduce_sum(p_soft * tf.nn.log_softmax(q), 1))\n",
        "    distance = tf.reduce_sum(p_soft * tf.nn.log_softmax(p) - p_soft * tf.nn.log_softmax(q))\n",
        "    # distance = plogp - plogq\n",
        "    return distance\n",
        " \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aeUAt_IUZbo4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building blocks for creating the networks"
      ]
    },
    {
      "metadata": {
        "id": "5YRC1mFK7RKs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "The model before AdD is applied\n",
        "'''\n",
        "def upperBlock(x, conv_size=[128, 256, 512, 256, 128], n_channels=3, is_train=True):\n",
        "    x = GaussianNoise(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=n_channels, n_filters=conv_size[0], padding='SAME', name='1a')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='1bna')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[0], name='1b')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='1bnb')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[0], name='1c')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='1bnc')\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "    x = Dropout(x, 0.5, is_train)\n",
        "    \n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[1], name='2a')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='2bna')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[1], name='2b')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='2bnb')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[1], name='2c')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='2bnc')\n",
        "    x = LeakyReLU(x)\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "    x = Dropout(x, 0.5, is_train)\n",
        "\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[2], padding='VALID', name='3a')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='3bna')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=1, n_channels=conv_size[2], n_filters=conv_size[3], name='3b')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='3bnb')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=1, n_channels=conv_size[3], n_filters=conv_size[4], name='3c')\n",
        "    x = Batch_Norm(x, axis=-1, is_train=True, momentum=0.999, name='3bnc')\n",
        "    x = LeakyReLU(x)\n",
        "    x = GlobalAveragePooling(x) \n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "'''\n",
        "The model after AdD is applied\n",
        "'''\n",
        "def lowerBlock(x, n_in=128, n_out=10, name='fc'):\n",
        "    x = Dense(x, n_in, n_out, name=name)\n",
        "    return x;\n",
        "\n",
        "\n",
        "'''\n",
        "Apply adv dropout\n",
        "'''\n",
        "def advDropout(x, mask, Jacobian, sigma=0.05, dim=128):\n",
        "    # y: output \n",
        "    # mask: current sampled dropout mask \n",
        "    # sigma: hyper-parameter for boundary \n",
        "    # Jabocian: Jacobian vector (gradient of divergence (or loss function))\n",
        "    # dim: layer dimension \n",
        "\n",
        "    Jacobian = tf.reshape(Jacobian, [-1, dim])\n",
        "\n",
        "    # mask = 0 --> -1 \n",
        "    mask = 2 * mask - tf.ones_like(mask)\n",
        "\n",
        "    adv_mask = mask \n",
        "\n",
        "    # extract the voxels for which the update conditions hold \n",
        "    # mask = 0 and J > 0 \n",
        "    # or\n",
        "    # mask = 1 and J < 1 \n",
        "    abs_jac = tf.abs(Jacobian)\n",
        "    temp = tf.cast(tf.greater(abs_jac, 0), tf.float32)\n",
        "    temp = 2 * temp - 1 \n",
        "    # interested in the cases when temp * mask = -1\n",
        "    ext = tf.cast(tf.less(mask, temp), tf.float32)\n",
        "\n",
        "    # keep the voxels that you want to update \n",
        "    candidates = abs_jac * ext \n",
        "    thres = tf.nn.top_k(candidates, int(dim * sigma * sigma)  + 1)[0][:,-1]\n",
        "\n",
        "    targets = tf.cast(tf.greater(candidates, tf.expand_dims(thres, -1)), tf.float32)\n",
        "\n",
        "    # get new mask \n",
        "    adv_mask = (mask - targets * 2 * mask + tf.ones_like(mask)) / 2.0\n",
        "\n",
        "    output = adv_mask * x\n",
        "\n",
        "    return output, adv_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkuyfHx7Zk8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "I-o9-MaZ7RxM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "''' Preprocesses the data '''\n",
        "def preprocess(data):\n",
        "    # Mean normalization\n",
        "    data = (data - 127.5) / 255.\n",
        "    # Find principal component\n",
        "    shape = data.shape\n",
        "    data = data.transpose(0, 2, 3, 1)\n",
        "    flatx = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2] * data.shape[3]))\n",
        "    sigma = np.dot(flatx.T, flatx) / flatx.shape[1]\n",
        "    U, S, V = np.linalg.svd(sigma)\n",
        "    pc = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 0.0001))), U.T)\n",
        "    # Apply ZCA whitening\n",
        "    whitex = np.dot(flatx, pc)\n",
        "    data = np.reshape(whitex, (shape[0], shape[1], shape[2], shape[3]))\n",
        "    return data\n",
        "\n",
        "\n",
        "'''\n",
        "Returns a model without adversarial dropout\n",
        "'''\n",
        "def modelWithRandD(x, n_channels=3, is_train=True):\n",
        "    x = upperBlock(x, n_channels=n_channels, is_train=is_train)\n",
        "    x = lowerBlock(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "'''\n",
        "Returns a model with adversarial dropout\n",
        "'''\n",
        "def modelWithAdD(x, y, fn_loss=KLDivergenceWithLogits, n_channels=3, is_train=True):\n",
        "    x = upperBlock(x, n_channels=n_channels, is_train=is_train)\n",
        "    y_no_adD = lowerBlock(x)\n",
        "    loss_no_adD = fn_loss(y_no_adD, y)\n",
        "\n",
        "    # Derivative of loss fn wrt x\n",
        "    DLoss = tf.gradients(loss_no_adD, [x])\n",
        "    DLoss = tf.squeeze(tf.stop_gradient(DLoss)) # Stops backpropagation\n",
        "\n",
        "    Jacobian_approx = DLoss * x\n",
        "    mask = tf.ones_like(x)\n",
        "\n",
        "    x, _ = advDropout(x, mask, Jacobian_approx)\n",
        "    x = lowerBlock(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def CreateBaseModel(x, y, learning_rate=0.001, optimizer=tf.train.AdamOptimizer, n_channels=3, is_train=True):\n",
        "    logit_rand = modelWithRandD(x, n_channels=n_channels)\n",
        "    loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "    opt = optimizer(learning_rate=learning_rate)\n",
        "    gradients = opt.compute_gradients(loss, tf.trainable_variables())\n",
        "    train_op = opt.apply_gradients(gradients)\n",
        "\n",
        "    return train_op, loss, logit_rand\n",
        "\n",
        "\n",
        "'''\n",
        "Create the AdD model for training\n",
        "'''\n",
        "def CreateAdDModel(x, y, learning_rate=0.001, optimizer=tf.train.AdamOptimizer, lmb=0.01, n_channels=3, is_train=True):\n",
        "    logit_rand = modelWithRandD(x, n_channels=n_channels, is_train=is_train)\n",
        "    logit_rand_loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
        "        # With adversarial dropout\n",
        "        logit_adD = modelWithAdD(x, y, n_channels=n_channels, is_train=is_train)\n",
        "        logit_adD_loss = CrossEntropyWithLogits(logit_adD, y)\n",
        "\n",
        "        # Total loss\n",
        "        loss = logit_rand_loss + lmb * logit_adD_loss\n",
        "\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        opt = optimizer(learning_rate=learning_rate)\n",
        "        gradients = opt.compute_gradients(loss, tf.trainable_variables())\n",
        "        train_op = opt.apply_gradients(gradients)        \n",
        "\n",
        "    return train_op, loss, logit_rand\n",
        "\n",
        "\n",
        "def CreateTestModel(x, y, n_channels=3, is_train=True):  \n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:         \n",
        "        logit_rand = modelWithRandD(x, n_channels=n_channels, is_train=is_train)\n",
        "        logit_rand_loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "        return logit_rand_loss, logit_rand\n",
        "\n",
        "\n",
        "def Accuracy(logits, labels):\n",
        "    y_pred = tf.argmax(logits, 1)\n",
        "    y_true = tf.argmax(labels, 1)\n",
        "    equality = tf.equal(y_pred, y_true)\n",
        "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
        "    return accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itE0hw-RyRte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Visualization functions"
      ]
    },
    {
      "metadata": {
        "id": "EqYhVsaCyRFO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Uncomment to download graphs from google colab\n",
        "'''\n",
        "from google.colab import files\n",
        "\n",
        "def visualize(trend, param):\n",
        "    name = \"Baseline\" if param['BASELINE'] else \"Adversarial\"\n",
        "    \n",
        "    for key, val in trend.items():\n",
        "        # X axis\n",
        "        x = np.arange(len(val))\n",
        "        # Acc or loss\n",
        "        title = re.sub(\"_\", \" \", key).capitalize()\n",
        "        plt.title(title + \" \" + name)\n",
        "        plt.plot(x, val)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy' if 'acc' in key else 'Loss')\n",
        "        filename = str(key + re.sub(\"{|}|:|'|,| \", \"\", str(param)) + \".png\")\n",
        "        print(filename)\n",
        "        plt.savefig(filename)\n",
        "        files.download(filename)\n",
        "        plt.close()\n",
        "        \n",
        "        \n",
        "def visualize_both(trend_base, trend_adv, param_base, param_adv):\n",
        "    for key in trend_base.keys():\n",
        "        # X axis\n",
        "        x = np.arange(min(len(trend_base[key]), len(trend_adv[key])))\n",
        "        # Acc or loss\n",
        "        title = re.sub(\"_\", \" \", key).capitalize()\n",
        "        plt.title(title)\n",
        "        plt.plot(x, trend_base[key][:len(x)], label='Base')\n",
        "        plt.plot(x, trend_adv[key][:len(x)], label='Adversarial')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy' if 'acc' in key else 'Loss')\n",
        "        plt.legend()\n",
        "        filename = str(key + '_both' + \".png\")\n",
        "        print(filename)\n",
        "        plt.savefig(filename)\n",
        "        files.download(filename)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vR2NxY1yYX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creates the graph with input/output nodes for training"
      ]
    },
    {
      "metadata": {
        "id": "nR_HLMEnaO1Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepareTrainingModel(param):\n",
        "    \n",
        "    n_channels = param['CHANNELS']\n",
        "    \n",
        "    with tf.variable_scope('Baseline' if param['BASELINE'] else 'Adversarial'):\n",
        "        # Graph\n",
        "        x_train_ph = tf.placeholder(tf.float32)\n",
        "        x_test_ph = tf.placeholder(tf.float32)\n",
        "        y_train_ph = tf.placeholder(tf.float32)\n",
        "        y_test_ph = tf.placeholder(tf.float32)\n",
        "\n",
        "        train_op, train_loss, train_logit = CreateBaseModel(x_train_ph, y_train_ph, n_channels=n_channels, is_train=True) if param['BASELINE'] else CreateAdDModel(\n",
        "            x_train_ph, y_train_ph, n_channels=n_channels, is_train=True)\n",
        "        test_loss, test_logit = CreateTestModel(x_test_ph, y_test_ph, n_channels=n_channels, is_train=False)\n",
        "\n",
        "        # Accuracy Train\n",
        "        train_accuracy = Accuracy(train_logit, y_train_ph)\n",
        "\n",
        "        # Accuracy Test\n",
        "        test_accuracy = Accuracy(test_logit, y_test_ph)  \n",
        "    \n",
        "    nodes = {\n",
        "        'x_train_ph': x_train_ph,\n",
        "        'x_test_ph': x_test_ph,\n",
        "        'y_train_ph': y_train_ph,\n",
        "        'y_test_ph': y_test_ph,\n",
        "        'train_op': train_op,\n",
        "        'train_loss': train_loss,\n",
        "        'train_logit': train_logit,\n",
        "        'test_logit': test_logit,\n",
        "        'test_loss': test_loss,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy,\n",
        "    }\n",
        "    \n",
        "    return nodes\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTfJBUiNyd9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Can perform training incrementally i.e. you do not need to run all epochs at once"
      ]
    },
    {
      "metadata": {
        "id": "ZttTkRv57Uc2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def doTraining(x_train, y_train, x_test, y_test, sess, nodes, param, trend, n_epochs=None):\n",
        "    # Training setup\n",
        "\n",
        "    batch_size = param['BATCH_SIZE']\n",
        "    epochs = param['EPOCHS'] if n_epochs is None else n_epochs\n",
        "    n_channels = x_train.shape[-1]\n",
        "\n",
        "    STEPS = len(x_train) // batch_size if param['STEPS'] is None else param['STEPS']\n",
        "    TEST_STEPS = len(x_test) // batch_size if param['STEPS'] is None else param['STEPS']\n",
        "     \n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        # Train model\n",
        "        acc_train, loss_train = 0, 0\n",
        "        for i in range(STEPS):\n",
        "            _, loss_, acc = sess.run([nodes['train_op'], nodes['train_loss'], nodes['train_accuracy']],\n",
        "                                     feed_dict={nodes['x_train_ph']: x_train[batch_size * i: batch_size * (i + 1)],\n",
        "                                                nodes['y_train_ph']: y_train[batch_size * i: batch_size * (i + 1)]})\n",
        "            acc_train += acc\n",
        "            loss_train += loss_\n",
        "\n",
        "        trend['acc_train_trend'].append(acc_train / STEPS)\n",
        "        trend['loss_train_trend'].append(loss_train / STEPS)\n",
        "\n",
        "        # Test model\n",
        "        acc_test, loss_test = 0, 0\n",
        "        for i in range(TEST_STEPS):\n",
        "            loss_t, acc_t = sess.run([nodes['test_loss'], nodes['test_accuracy']],\n",
        "                                     feed_dict={nodes['x_test_ph']: x_test[batch_size * i: batch_size * (i + 1)],\n",
        "                                                nodes['y_test_ph']: y_test[batch_size * i: batch_size * (i + 1)]})\n",
        "            acc_test += acc_t\n",
        "            loss_test += loss_t\n",
        "\n",
        "        trend['acc_test_trend'].append(acc_test / TEST_STEPS)\n",
        "        trend['loss_test_trend'].append(loss_test / TEST_STEPS)\n",
        "\n",
        "        print('Epoch: {} || Train Loss: {}, Train Acc: {} || Test Loss: {}, Test Accuracy: {}'.format(epoch,\n",
        "                                                                                                      loss_train / STEPS,\n",
        "                                                                                                      acc_train / STEPS,\n",
        "                                                                                                      loss_test / TEST_STEPS,\n",
        "                                                                                                      acc_test / TEST_STEPS))\n",
        "                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lchJVuU-yuue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data I/O and preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "gQ-V2jEK3azu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWM6pXCr3gyy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# with tf.Session() as sess:\n",
        "#     x_train = sess.run(tf.image.rgb_to_grayscale(x_train)) / 255\n",
        "#     x_test = sess.run(tf.image.rgb_to_grayscale(x_test)) / 255\n",
        "x_train, x_test = preprocess(x_train), preprocess(x_test)\n",
        "    \n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHxeKmTxe8Ni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adversarial Dropout training"
      ]
    },
    {
      "metadata": {
        "id": "klD2_w9w7yS4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "param_adv = {\n",
        "    'CHANNELS': 3,\n",
        "    'BATCH_SIZE': 100,\n",
        "    'EPOCHS': 50,\n",
        "    'STEPS': None,\n",
        "    'BASELINE': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inJ-I4gQjY-N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Run this to delete default graph w/o having to restart notebook\n",
        "'''\n",
        "# tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKr9xYdbe5nq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nodes_adv = prepareTrainingModel(param_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALKRJKi5fHN6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trend_adv = {\n",
        "    'acc_train_trend': [],\n",
        "    'loss_train_trend': [],\n",
        "    'acc_test_trend': [],\n",
        "    'loss_test_trend': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnQ7IlKvrvp3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess_adv = tf.Session()\n",
        "sess_adv.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSm4U-yJ1dQs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "08168139-c544-4a00-c383-ecc8e797125d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523999533288,
          "user_tz": 240,
          "elapsed": 2141715,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_adv, nodes_adv, param_adv, trend_adv, n_epochs=10)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 1.620110316991806, Train Acc: 0.4129999985992909 || Test Loss: 1.2717525166273118, Test Accuracy: 0.5419999977946282\n",
            "Epoch: 1 || Train Loss: 1.2598333572149276, Train Acc: 0.5546799973249436 || Test Loss: 1.0823384922742845, Test Accuracy: 0.621099999845028\n",
            "Epoch: 2 || Train Loss: 1.1138328193426132, Train Acc: 0.610099999666214 || Test Loss: 0.9574610203504562, Test Accuracy: 0.6692000007629395\n",
            "Epoch: 3 || Train Loss: 1.0106067848205567, Train Acc: 0.6480200009346009 || Test Loss: 0.8615555489063262, Test Accuracy: 0.700400002002716\n",
            "Epoch: 4 || Train Loss: 0.9376442730426788, Train Acc: 0.6732400019168854 || Test Loss: 0.8257872021198273, Test Accuracy: 0.7164000022411346\n",
            "Epoch: 5 || Train Loss: 0.8856502976417542, Train Acc: 0.6921800022125244 || Test Loss: 0.778647956252098, Test Accuracy: 0.7312000012397766\n",
            "Epoch: 6 || Train Loss: 0.8425833998918534, Train Acc: 0.7071600006818771 || Test Loss: 0.7530433434247971, Test Accuracy: 0.7382000005245208\n",
            "Epoch: 7 || Train Loss: 0.8053955000638962, Train Acc: 0.7215800009965897 || Test Loss: 0.7256195318698883, Test Accuracy: 0.7536999994516372\n",
            "Epoch: 8 || Train Loss: 0.7719254809617996, Train Acc: 0.7319800008535385 || Test Loss: 0.6956189605593681, Test Accuracy: 0.7617000013589859\n",
            "Epoch: 9 || Train Loss: 0.7404039055109024, Train Acc: 0.7422199994325638 || Test Loss: 0.6726563468575477, Test Accuracy: 0.7697999989986419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "76sXLEsQeDnq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "e697b7a0-3a18-4527-cf3c-a2e8e3b61a58",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524008669772,
          "user_tz": 240,
          "elapsed": 8792059,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_adv, nodes_adv, param_adv, trend_adv, n_epochs=40)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 0.7158123844265938, Train Acc: 0.7516199982166291 || Test Loss: 0.6704400649666786, Test Accuracy: 0.7714000010490417\n",
            "Epoch: 1 || Train Loss: 0.6866864419579506, Train Acc: 0.7600599995851517 || Test Loss: 0.657285475730896, Test Accuracy: 0.7787999957799911\n",
            "Epoch: 2 || Train Loss: 0.6669026043415069, Train Acc: 0.7685799983739853 || Test Loss: 0.6399628001451493, Test Accuracy: 0.784899999499321\n",
            "Epoch: 3 || Train Loss: 0.6464293702244759, Train Acc: 0.7760199990272522 || Test Loss: 0.6306747069954872, Test Accuracy: 0.7871999973058701\n",
            "Epoch: 4 || Train Loss: 0.6296521626114845, Train Acc: 0.7805399976968765 || Test Loss: 0.6239123818278313, Test Accuracy: 0.7900999993085861\n",
            "Epoch: 5 || Train Loss: 0.6066504675745964, Train Acc: 0.7897199989557266 || Test Loss: 0.6041067487001419, Test Accuracy: 0.7974999976158142\n",
            "Epoch: 6 || Train Loss: 0.5888659143447876, Train Acc: 0.7949599971771241 || Test Loss: 0.6097107145190239, Test Accuracy: 0.7976999998092651\n",
            "Epoch: 7 || Train Loss: 0.5703451691269874, Train Acc: 0.8018999979496002 || Test Loss: 0.6049979814887047, Test Accuracy: 0.8006999975442887\n",
            "Epoch: 8 || Train Loss: 0.5568659057021141, Train Acc: 0.8063599970340729 || Test Loss: 0.5943265503644943, Test Accuracy: 0.8052999973297119\n",
            "Epoch: 9 || Train Loss: 0.5383605663776397, Train Acc: 0.8131399985551834 || Test Loss: 0.6035645115375519, Test Accuracy: 0.803099998831749\n",
            "Epoch: 10 || Train Loss: 0.5265508559942246, Train Acc: 0.8183399978876114 || Test Loss: 0.6004054382443428, Test Accuracy: 0.799099998474121\n",
            "Epoch: 11 || Train Loss: 0.5148104073405266, Train Acc: 0.8217599995136261 || Test Loss: 0.587552878856659, Test Accuracy: 0.807299997806549\n",
            "Epoch: 12 || Train Loss: 0.49479871314764023, Train Acc: 0.8295399980545044 || Test Loss: 0.5935460212826729, Test Accuracy: 0.807599995136261\n",
            "Epoch: 13 || Train Loss: 0.48573611187934873, Train Acc: 0.8318399982452392 || Test Loss: 0.5953748047351837, Test Accuracy: 0.8099999976158142\n",
            "Epoch: 14 || Train Loss: 0.4772863009572029, Train Acc: 0.8318599976301193 || Test Loss: 0.6038454902172089, Test Accuracy: 0.8075999999046326\n",
            "Epoch: 15 || Train Loss: 0.4632819053530693, Train Acc: 0.8374999978542328 || Test Loss: 0.597032784819603, Test Accuracy: 0.8144000011682511\n",
            "Epoch: 16 || Train Loss: 0.447874833971262, Train Acc: 0.8429999986886978 || Test Loss: 0.5956624978780747, Test Accuracy: 0.8144999957084655\n",
            "Epoch: 17 || Train Loss: 0.43961759939789774, Train Acc: 0.8456999992132187 || Test Loss: 0.5944630143046379, Test Accuracy: 0.818099998831749\n",
            "Epoch: 18 || Train Loss: 0.42934016439318656, Train Acc: 0.8495799980163574 || Test Loss: 0.5895685917139053, Test Accuracy: 0.8183999979496002\n",
            "Epoch: 19 || Train Loss: 0.4226417151093483, Train Acc: 0.8511999995708466 || Test Loss: 0.6096962201595306, Test Accuracy: 0.8112999993562698\n",
            "Epoch: 20 || Train Loss: 0.41390544733405116, Train Acc: 0.8553999987840653 || Test Loss: 0.6249852839112282, Test Accuracy: 0.8088999992609024\n",
            "Epoch: 21 || Train Loss: 0.40064692464470864, Train Acc: 0.8590999987125397 || Test Loss: 0.6064320462942123, Test Accuracy: 0.8168000000715255\n",
            "Epoch: 22 || Train Loss: 0.39862930157780646, Train Acc: 0.8596199984550477 || Test Loss: 0.6024235409498214, Test Accuracy: 0.8168999987840653\n",
            "Epoch: 23 || Train Loss: 0.388176819562912, Train Acc: 0.8634799996614456 || Test Loss: 0.61257483959198, Test Accuracy: 0.8197999978065491\n",
            "Epoch: 24 || Train Loss: 0.3793207197189331, Train Acc: 0.8662799996137619 || Test Loss: 0.6073556634783744, Test Accuracy: 0.8208999991416931\n",
            "Epoch: 25 || Train Loss: 0.3700087436437607, Train Acc: 0.8697199990749359 || Test Loss: 0.6059430742263794, Test Accuracy: 0.8200999975204468\n",
            "Epoch: 26 || Train Loss: 0.36129943397641184, Train Acc: 0.8731400009393692 || Test Loss: 0.6132257011532783, Test Accuracy: 0.8181999957561493\n",
            "Epoch: 27 || Train Loss: 0.35962298008799554, Train Acc: 0.8730400003194809 || Test Loss: 0.610167843401432, Test Accuracy: 0.8236999958753586\n",
            "Epoch: 28 || Train Loss: 0.3508672679364681, Train Acc: 0.8755400004386902 || Test Loss: 0.6258398103713989, Test Accuracy: 0.8226999950408935\n",
            "Epoch: 29 || Train Loss: 0.3466671301424503, Train Acc: 0.8766200014352798 || Test Loss: 0.6003183886408806, Test Accuracy: 0.8284999960660935\n",
            "Epoch: 30 || Train Loss: 0.33937602731585503, Train Acc: 0.8799800009727478 || Test Loss: 0.6415675833821297, Test Accuracy: 0.8180999970436096\n",
            "Epoch: 31 || Train Loss: 0.330676244109869, Train Acc: 0.8822799994945526 || Test Loss: 0.6261389204859733, Test Accuracy: 0.8249999976158142\n",
            "Epoch: 32 || Train Loss: 0.3303339136838913, Train Acc: 0.8826799991130829 || Test Loss: 0.6295629897713662, Test Accuracy: 0.8248999977111816\n",
            "Epoch: 33 || Train Loss: 0.318315786242485, Train Acc: 0.8882600014209747 || Test Loss: 0.6432505503296853, Test Accuracy: 0.8212999963760376\n",
            "Epoch: 34 || Train Loss: 0.3239959905743599, Train Acc: 0.8857599997520447 || Test Loss: 0.6105097752809524, Test Accuracy: 0.8267999982833862\n",
            "Epoch: 35 || Train Loss: 0.31264540457725526, Train Acc: 0.8906200006008148 || Test Loss: 0.6251688408851623, Test Accuracy: 0.8267999994754791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 || Train Loss: 0.30994190934300425, Train Acc: 0.8909200005531311 || Test Loss: 0.6472965139150619, Test Accuracy: 0.8221999990940094\n",
            "Epoch: 37 || Train Loss: 0.30209072713553903, Train Acc: 0.893200000166893 || Test Loss: 0.6558462485671044, Test Accuracy: 0.8188999968767167\n",
            "Epoch: 38 || Train Loss: 0.2970891007483005, Train Acc: 0.8960400013923645 || Test Loss: 0.6450983291864395, Test Accuracy: 0.8267999964952469\n",
            "Epoch: 39 || Train Loss: 0.2956283106803894, Train Acc: 0.89634000146389 || Test Loss: 0.6504785293340682, Test Accuracy: 0.8233999997377396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t2QJGyHT_45A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "dbf4bb0c-37fd-4ead-bbea-78660310c428",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524013338003,
          "user_tz": 240,
          "elapsed": 4273074,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_adv, nodes_adv, param_adv, trend_adv, n_epochs=20)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 0.28926089495420454, Train Acc: 0.898240000128746 || Test Loss: 0.6452942350506783, Test Accuracy: 0.8263999986648559\n",
            "Epoch: 1 || Train Loss: 0.28459110695123674, Train Acc: 0.8992600003480912 || Test Loss: 0.6613492301106453, Test Accuracy: 0.8210999977588653\n",
            "Epoch: 2 || Train Loss: 0.2812925135493278, Train Acc: 0.901300000667572 || Test Loss: 0.6619101724028588, Test Accuracy: 0.8210999977588653\n",
            "Epoch: 3 || Train Loss: 0.276981046333909, Train Acc: 0.9019400004148483 || Test Loss: 0.64685526907444, Test Accuracy: 0.8249999988079071\n",
            "Epoch: 4 || Train Loss: 0.27071644307672976, Train Acc: 0.9037400007247924 || Test Loss: 0.6614064973592758, Test Accuracy: 0.8246999984979629\n",
            "Epoch: 5 || Train Loss: 0.2748752849698067, Train Acc: 0.9031199998855591 || Test Loss: 0.6581308054924011, Test Accuracy: 0.8269999974966049\n",
            "Epoch: 6 || Train Loss: 0.27009704434871673, Train Acc: 0.90432000207901 || Test Loss: 0.6601120835542679, Test Accuracy: 0.8259999978542328\n",
            "Epoch: 7 || Train Loss: 0.2654034191668034, Train Acc: 0.904860000371933 || Test Loss: 0.6576899644732476, Test Accuracy: 0.8253999972343444\n",
            "Epoch: 8 || Train Loss: 0.2640030241012573, Train Acc: 0.9065800005197525 || Test Loss: 0.6701600679755211, Test Accuracy: 0.8258000004291535\n",
            "Epoch: 9 || Train Loss: 0.25569714249670505, Train Acc: 0.9100200029611587 || Test Loss: 0.6505714645981788, Test Accuracy: 0.8290000003576279\n",
            "Epoch: 10 || Train Loss: 0.2559702453315258, Train Acc: 0.9108200017213821 || Test Loss: 0.660320355296135, Test Accuracy: 0.8304999953508377\n",
            "Epoch: 11 || Train Loss: 0.24700212188065052, Train Acc: 0.9124200016260147 || Test Loss: 0.6951382672786712, Test Accuracy: 0.8225999975204468\n",
            "Epoch: 12 || Train Loss: 0.24860084109008312, Train Acc: 0.9130200018882751 || Test Loss: 0.6829315212368965, Test Accuracy: 0.8274999970197677\n",
            "Epoch: 13 || Train Loss: 0.2444529318511486, Train Acc: 0.9123000020980835 || Test Loss: 0.6826004239916802, Test Accuracy: 0.8267999982833862\n",
            "Epoch: 14 || Train Loss: 0.24104287795722484, Train Acc: 0.9155600010156631 || Test Loss: 0.6955550980567932, Test Accuracy: 0.824399995803833\n",
            "Epoch: 15 || Train Loss: 0.23964037996530532, Train Acc: 0.9148000017404556 || Test Loss: 0.6709437471628189, Test Accuracy: 0.8289999997615815\n",
            "Epoch: 16 || Train Loss: 0.24143787570297717, Train Acc: 0.9153200010061264 || Test Loss: 0.7046778002381324, Test Accuracy: 0.8228999984264374\n",
            "Epoch: 17 || Train Loss: 0.2367564363181591, Train Acc: 0.9160600017309188 || Test Loss: 0.6897948551177978, Test Accuracy: 0.8280999970436096\n",
            "Epoch: 18 || Train Loss: 0.23369396394491196, Train Acc: 0.9168200024366379 || Test Loss: 0.6977140921354293, Test Accuracy: 0.8311999988555908\n",
            "Epoch: 19 || Train Loss: 0.22918433701992036, Train Acc: 0.9191600018739701 || Test Loss: 0.6954920724034309, Test Accuracy: 0.8251999980211258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MOTkA8amjDQy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('adv_trend.json', 'w') as fp:\n",
        "    json.dump(trend_adv, fp)\n",
        "files.download('adv_trend.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlfkuFMHXpFn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "abaa3def-c359-4e4f-edd6-f687dc8e5d5f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524013356647,
          "user_tz": 240,
          "elapsed": 2408,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize(trend_adv, param_adv)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "loss_train_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "acc_test_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "loss_test_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINEFalse.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXLHPa13bsP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline Training"
      ]
    },
    {
      "metadata": {
        "id": "VaJHqe25bud3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "param_base = {\n",
        "    'CHANNELS': 3,\n",
        "    'BATCH_SIZE': 100,\n",
        "    'EPOCHS': 50,\n",
        "    'STEPS': None,\n",
        "    'BASELINE': True\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_1a-gb_byBP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nodes_base = prepareTrainingModel(param_base)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "390LlVp2b2gI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trend_base = {\n",
        "    'acc_train_trend': [],\n",
        "    'loss_train_trend': [],\n",
        "    'acc_test_trend': [],\n",
        "    'loss_test_trend': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vrlfTDnab6WI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess_base = tf.Session()\n",
        "sess_base.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbHu1L1pc3-O",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "986a3418-bc0b-4718-c9f9-45b8a8e01b35",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524018903013,
          "user_tz": 240,
          "elapsed": 5506384,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_base, nodes_base, param_base, trend_base, n_epochs=50)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 1.6085399551391601, Train Acc: 0.41087999918311835 || Test Loss: 1.2658606195449829, Test Accuracy: 0.5464999970793724\n",
            "Epoch: 1 || Train Loss: 1.2566290135383607, Train Acc: 0.5512999967336655 || Test Loss: 1.0664029359817504, Test Accuracy: 0.6236999964714051\n",
            "Epoch: 2 || Train Loss: 1.1168474978208542, Train Acc: 0.6023199974298478 || Test Loss: 0.9503870350122452, Test Accuracy: 0.6666000032424927\n",
            "Epoch: 3 || Train Loss: 1.0164762270450591, Train Acc: 0.6425400001406669 || Test Loss: 0.8758441573381424, Test Accuracy: 0.6956000036001205\n",
            "Epoch: 4 || Train Loss: 0.9459592801332474, Train Acc: 0.6686400018930435 || Test Loss: 0.8247440886497498, Test Accuracy: 0.7176999992132187\n",
            "Epoch: 5 || Train Loss: 0.8916789782047272, Train Acc: 0.6862600003480911 || Test Loss: 0.7887231945991516, Test Accuracy: 0.7306000006198883\n",
            "Epoch: 6 || Train Loss: 0.841057443022728, Train Acc: 0.7055800009965897 || Test Loss: 0.7609857788681984, Test Accuracy: 0.7396000015735626\n",
            "Epoch: 7 || Train Loss: 0.8047877289056778, Train Acc: 0.717840001821518 || Test Loss: 0.7386121755838394, Test Accuracy: 0.7478999990224838\n",
            "Epoch: 8 || Train Loss: 0.7700298412442207, Train Acc: 0.7301200004816055 || Test Loss: 0.727434002161026, Test Accuracy: 0.7495999997854232\n",
            "Epoch: 9 || Train Loss: 0.7416945770978928, Train Acc: 0.7365999994277954 || Test Loss: 0.6922051221132278, Test Accuracy: 0.7629000025987626\n",
            "Epoch: 10 || Train Loss: 0.7162141221761703, Train Acc: 0.748200000166893 || Test Loss: 0.6746257928013801, Test Accuracy: 0.7723999989032745\n",
            "Epoch: 11 || Train Loss: 0.6899458965659142, Train Acc: 0.7611199997663498 || Test Loss: 0.6520267254114152, Test Accuracy: 0.7769999969005584\n",
            "Epoch: 12 || Train Loss: 0.6650478215813637, Train Acc: 0.7665000004768372 || Test Loss: 0.6602374896407127, Test Accuracy: 0.7750999969244003\n",
            "Epoch: 13 || Train Loss: 0.6475333735346794, Train Acc: 0.7729599982500076 || Test Loss: 0.642977991104126, Test Accuracy: 0.7860999983549118\n",
            "Epoch: 14 || Train Loss: 0.6272324748635292, Train Acc: 0.7822199980020523 || Test Loss: 0.6211397460103035, Test Accuracy: 0.793099998831749\n",
            "Epoch: 15 || Train Loss: 0.6028650238513946, Train Acc: 0.787619997382164 || Test Loss: 0.633555720448494, Test Accuracy: 0.7831999999284744\n",
            "Epoch: 16 || Train Loss: 0.5894386876225471, Train Acc: 0.792259998202324 || Test Loss: 0.6294322940707207, Test Accuracy: 0.7882999962568283\n",
            "Epoch: 17 || Train Loss: 0.575156265258789, Train Acc: 0.7974399981498719 || Test Loss: 0.6148067253828049, Test Accuracy: 0.7947999960184098\n",
            "Epoch: 18 || Train Loss: 0.5565529039502144, Train Acc: 0.8050999971628189 || Test Loss: 0.6026858538389206, Test Accuracy: 0.7968000012636185\n",
            "Epoch: 19 || Train Loss: 0.5370953871011734, Train Acc: 0.8115999985933304 || Test Loss: 0.601434266269207, Test Accuracy: 0.8018999975919724\n",
            "Epoch: 20 || Train Loss: 0.5284673062562942, Train Acc: 0.8141399992704391 || Test Loss: 0.6131825944781304, Test Accuracy: 0.8009999984502792\n",
            "Epoch: 21 || Train Loss: 0.517034081876278, Train Acc: 0.8170799975395202 || Test Loss: 0.5984755784273148, Test Accuracy: 0.8092999976873397\n",
            "Epoch: 22 || Train Loss: 0.5010254059433937, Train Acc: 0.8226599986553192 || Test Loss: 0.6022983607649803, Test Accuracy: 0.8048999977111816\n",
            "Epoch: 23 || Train Loss: 0.48323382103443147, Train Acc: 0.8282199989557266 || Test Loss: 0.5973783931136132, Test Accuracy: 0.8122999984025955\n",
            "Epoch: 24 || Train Loss: 0.4772506160736084, Train Acc: 0.8324399993419648 || Test Loss: 0.6103448954224586, Test Accuracy: 0.8066999995708466\n",
            "Epoch: 25 || Train Loss: 0.4633060781955719, Train Acc: 0.8361199983358383 || Test Loss: 0.6122305795550347, Test Accuracy: 0.8059999996423721\n",
            "Epoch: 26 || Train Loss: 0.45494536608457564, Train Acc: 0.8391999992132186 || Test Loss: 0.595791308581829, Test Accuracy: 0.8104999983310699\n",
            "Epoch: 27 || Train Loss: 0.44066980028152464, Train Acc: 0.8439999982118607 || Test Loss: 0.6091404435038567, Test Accuracy: 0.8111999982595444\n",
            "Epoch: 28 || Train Loss: 0.43684509882330896, Train Acc: 0.8436399983167648 || Test Loss: 0.6211754596233368, Test Accuracy: 0.8099000000953674\n",
            "Epoch: 29 || Train Loss: 0.4277905865609646, Train Acc: 0.8482799996137619 || Test Loss: 0.6269477665424347, Test Accuracy: 0.8072999984025955\n",
            "Epoch: 30 || Train Loss: 0.4091639888882637, Train Acc: 0.8536399976015091 || Test Loss: 0.6025395411252975, Test Accuracy: 0.8177999991178513\n",
            "Epoch: 31 || Train Loss: 0.4074798901975155, Train Acc: 0.8554199985265731 || Test Loss: 0.6137022659182548, Test Accuracy: 0.8160999983549118\n",
            "Epoch: 32 || Train Loss: 0.39488217839598655, Train Acc: 0.8584599995613098 || Test Loss: 0.6175658452510834, Test Accuracy: 0.8144999980926514\n",
            "Epoch: 33 || Train Loss: 0.38514826747775077, Train Acc: 0.8624600000381469 || Test Loss: 0.6128851374983788, Test Accuracy: 0.8159999978542328\n",
            "Epoch: 34 || Train Loss: 0.38300665411353113, Train Acc: 0.8631999996900559 || Test Loss: 0.6167043471336364, Test Accuracy: 0.8177999943494797\n",
            "Epoch: 35 || Train Loss: 0.377523035466671, Train Acc: 0.8668799998760224 || Test Loss: 0.6208286622166633, Test Accuracy: 0.8136999976634979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 || Train Loss: 0.36685942676663397, Train Acc: 0.8688600002527237 || Test Loss: 0.6288772609829902, Test Accuracy: 0.8175999957323075\n",
            "Epoch: 37 || Train Loss: 0.36233904108405113, Train Acc: 0.8706200001239777 || Test Loss: 0.6085212418437004, Test Accuracy: 0.8188000005483628\n",
            "Epoch: 38 || Train Loss: 0.35268817690014836, Train Acc: 0.8732400002479553 || Test Loss: 0.6314712625741958, Test Accuracy: 0.8154999977350235\n",
            "Epoch: 39 || Train Loss: 0.3503491114675999, Train Acc: 0.8766800001859665 || Test Loss: 0.6209696188569069, Test Accuracy: 0.8194999986886978\n",
            "Epoch: 40 || Train Loss: 0.3353552449941635, Train Acc: 0.8809000005722046 || Test Loss: 0.6351635047793388, Test Accuracy: 0.819899998307228\n",
            "Epoch: 41 || Train Loss: 0.33653587263822554, Train Acc: 0.8797399991750717 || Test Loss: 0.6309032583236694, Test Accuracy: 0.8195999962091446\n",
            "Epoch: 42 || Train Loss: 0.32838118724524973, Train Acc: 0.8820000015497208 || Test Loss: 0.6379388278722763, Test Accuracy: 0.818899998664856\n",
            "Epoch: 43 || Train Loss: 0.32213130977749826, Train Acc: 0.8855200002193451 || Test Loss: 0.6536169916391372, Test Accuracy: 0.8165000003576278\n",
            "Epoch: 44 || Train Loss: 0.3184320965856314, Train Acc: 0.8857000005245209 || Test Loss: 0.6487707790732383, Test Accuracy: 0.8205999976396561\n",
            "Epoch: 45 || Train Loss: 0.31117382472753524, Train Acc: 0.8898400003910065 || Test Loss: 0.643886206150055, Test Accuracy: 0.819899998307228\n",
            "Epoch: 46 || Train Loss: 0.3126063561141491, Train Acc: 0.8884999996423721 || Test Loss: 0.6618428960442543, Test Accuracy: 0.8185000002384186\n",
            "Epoch: 47 || Train Loss: 0.3009173205941916, Train Acc: 0.8938599997758865 || Test Loss: 0.6645158535242081, Test Accuracy: 0.8202999991178512\n",
            "Epoch: 48 || Train Loss: 0.29782524216175077, Train Acc: 0.8951400007009507 || Test Loss: 0.6602706623077392, Test Accuracy: 0.8196000003814697\n",
            "Epoch: 49 || Train Loss: 0.29296911831200123, Train Acc: 0.8947399995326996 || Test Loss: 0.682461034655571, Test Accuracy: 0.8140999960899353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BuZBeP_Fc-h2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('base_trend.json', 'w') as fp:\n",
        "    json.dump(trend_base, fp)\n",
        "files.download('base_trend.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsSFXhRotGdV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "15990222-fa11-4d80-a996-e1e01081b954",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524025495930,
          "user_tz": 240,
          "elapsed": 2445,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize(trend_base, param_base)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINETrue.png\n",
            "loss_train_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINETrue.png\n",
            "acc_test_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINETrue.png\n",
            "loss_test_trendCHANNELS3BATCH_SIZE100EPOCHS50STEPSNoneBASELINETrue.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5kDIKFYytJn8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "30b59433-3b1d-473e-a733-0266aae91972",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524025647216,
          "user_tz": 240,
          "elapsed": 2388,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize_both(trend_base, trend_adv, param_base, param_adv)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trend_both.png\n",
            "loss_train_trend_both.png\n",
            "acc_test_trend_both.png\n",
            "loss_test_trend_both.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D6esozSLAAEj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}