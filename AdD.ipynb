{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdD.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UdoHEU7TZM3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adversarial Dropout Code\n",
        "#### This file contains the code used to replicate the results of Adversarial Dropout"
      ]
    },
    {
      "metadata": {
        "id": "yNPBWy4_vAu3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "492041ce-ea89-4dc2-d62b-5e20c712f818",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523922637634,
          "user_tz": 240,
          "elapsed": 1145,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "d0G1RJtjY5gx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "4WzEOO-77L24",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 123456\n",
        "rng = np.random.RandomState(SEED)\n",
        "\n",
        "\n",
        "def __createWeights(shape, seed=None, name='weight'):\n",
        "    w_init = tf.contrib.layers.variance_scaling_initializer(seed=seed)\n",
        "    return tf.get_variable(name + '_w', shape=shape, initializer=w_init)\n",
        "    \n",
        "\n",
        "def __createBiases(size, name='bias'):\n",
        "    return tf.get_variable(name + '_b', shape=[size], initializer=tf.constant_initializer(0.0))\n",
        "\n",
        "\n",
        "def LeakyReLU(x, alpha=0.1):\n",
        "    x = tf.nn.leaky_relu(x, alpha=alpha)\n",
        "    return x\n",
        "\n",
        "\n",
        "def MaxPooling(x, ksize=2, stride_length=2, padding='SAME', data_format='NHWC'):\n",
        "    x = tf.nn.max_pool(x, (1, ksize, ksize, 1), (1, stride_length, stride_length, 1), padding, data_format)\n",
        "    return x\n",
        "\n",
        "\n",
        "def GlobalAveragePooling(x):\n",
        "    x = tf.reduce_mean(x, [1, 2])\n",
        "    return x\n",
        "\n",
        "\n",
        "def Dense(x, input_dim, output_dim, seed=None, name='dense'):\n",
        "    W = __createWeights([input_dim, output_dim], seed, name) \n",
        "    b = __createBiases(output_dim, name) \n",
        "    x = tf.nn.xw_plus_b(x, W, b)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Conv2D(x, filter_size, n_channels, n_filters, stride_length=1, padding='SAME', data_format='NHWC', name='conv'):\n",
        "    shape = [filter_size, filter_size, n_channels, n_filters]\n",
        "    W = __createWeights(shape, name=name)\n",
        "    b = __createBiases(n_filters, name=name)\n",
        "    x = tf.nn.conv2d(x, filter=W, strides=(1, stride_length, stride_length, 1), padding=padding, data_format=data_format)\n",
        "    x += b\n",
        "    return x\n",
        "\n",
        "\n",
        "def Dropout(x, probability=0.5):\n",
        "    x = tf.nn.dropout(x, keep_prob=probability, seed=rng.randint(SEED))\n",
        "    return x\n",
        "\n",
        "\n",
        "def GaussianNoise(x, sigma=0.15):\n",
        "    noise = tf.random_normal(shape=tf.shape(x), stddev=sigma)\n",
        "    x += noise\n",
        "    return x\n",
        "\n",
        "\n",
        "def SoftMax(x):\n",
        "    x = tf.nn.softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Loss functions. Arg 1: Approximation, Arg 2: Labels\n",
        "'''\n",
        "def CrossEntropyWithLogits(logits, labels):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Formula: sum(p_i * log(p_i) - p_i * log(q_i))\n",
        "def KLDivergenceWithLogits(q, p):\n",
        "    p_soft = SoftMax(p)\n",
        "    # plogp = tf.reduce_mean(tf.reduce_sum(p_soft * tf.nn.log_softmax(p), 1))\n",
        "    # plogq = tf.reduce_mean(tf.reduce_sum(p_soft * tf.nn.log_softmax(q), 1))\n",
        "    distance = tf.reduce_sum(p_soft * tf.nn.log_softmax(p) - p_soft * tf.nn.log_softmax(q))\n",
        "    # distance = plogp - plogq\n",
        "    return distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aeUAt_IUZbo4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building blocks for creating the networks"
      ]
    },
    {
      "metadata": {
        "id": "5YRC1mFK7RKs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "The model before AdD is applied\n",
        "'''\n",
        "def upperBlock(x, conv_size=[128, 256, 512, 256,128], n_channels=3):\n",
        "    x = GaussianNoise(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=n_channels, n_filters=conv_size[0], padding='SAME', name='1a')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[0], name='1b')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[0], name='1c')\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "    x = Dropout(x, probability=0.5)\n",
        "    \n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[0], n_filters=conv_size[1], name='2a')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[1], name='2b')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[1], name='2c')\n",
        "    x = LeakyReLU(x)\n",
        "    x = MaxPooling(x, ksize=2, stride_length=2)\n",
        "\n",
        "    x = Conv2D(x, filter_size=3, n_channels=conv_size[1], n_filters=conv_size[2], padding='VALID', name='3a')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=1, n_channels=conv_size[2], n_filters=conv_size[3], name='3b')\n",
        "    x = LeakyReLU(x)\n",
        "    x = Conv2D(x, filter_size=1, n_channels=conv_size[3], n_filters=conv_size[4], name='3c')\n",
        "    x = LeakyReLU(x)\n",
        "    x = GlobalAveragePooling(x) \n",
        "    \n",
        "    # x = Dropout(x, probability=0.5)\n",
        "    # x = Dense(x, conv_size[4], 10)\n",
        "    # x = SoftMax(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "'''\n",
        "The model after AdD is applied\n",
        "'''\n",
        "def lowerBlock(x, n_in=128, n_out=10, name='fc'):\n",
        "    x = Dense(x, n_in, n_out, name=name)\n",
        "    return x;\n",
        "\n",
        "\n",
        "'''\n",
        "Apply adv dropout\n",
        "'''\n",
        "def advDropout(x, mask, Jacobian, sigma=0.05, dim=128):\n",
        "    # y: output \n",
        "    # mask: current sampled dropout mask \n",
        "    # sigma: hyper-parameter for boundary \n",
        "    # Jabocian: Jacobian vector (gradient of divergence (or loss function))\n",
        "    # dim: layer dimension \n",
        "\n",
        "    Jacobian = tf.reshape(Jacobian, [-1, dim])\n",
        "\n",
        "    # mask = 0 --> -1 \n",
        "    mask = 2 * mask - tf.ones_like(mask)\n",
        "\n",
        "    adv_mask = mask \n",
        "\n",
        "    # extract the voxels for which the update conditions hold \n",
        "    # mask = 0 and J > 0 \n",
        "    # or\n",
        "    # mask = 1 and J < 1 \n",
        "    abs_jac = tf.abs(Jacobian)\n",
        "    temp = tf.cast(tf.greater(abs_jac, 0), tf.float32)\n",
        "    temp = 2 * temp - 1 \n",
        "    # interested in the cases when temp * mask = -1\n",
        "    ext = tf.cast(tf.less(mask, temp), tf.float32)\n",
        "\n",
        "    # keep the voxels that you want to update \n",
        "    candidates = abs_jac * ext \n",
        "    thres = tf.nn.top_k(candidates, int(dim * sigma * sigma)  + 1)[0][:,-1]\n",
        "\n",
        "    targets = tf.cast(tf.greater(candidates, tf.expand_dims(thres, -1)), tf.float32)\n",
        "\n",
        "    # get new mask \n",
        "    adv_mask = (mask - targets * 2 * mask + tf.ones_like(mask)) / 2.0\n",
        "\n",
        "    output = adv_mask * x\n",
        "\n",
        "    return output, adv_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkuyfHx7Zk8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "I-o9-MaZ7RxM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "''' Preprocesses the data '''\n",
        "def preprocess(data):\n",
        "    # Mean normalization\n",
        "    data = (data - 127.5) / 255.\n",
        "    # Find principal component\n",
        "    shape = data.shape\n",
        "    data = data.transpose(0, 2, 3, 1)\n",
        "    flatx = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2] * data.shape[3]))\n",
        "    sigma = np.dot(flatx.T, flatx) / flatx.shape[1]\n",
        "    U, S, V = np.linalg.svd(sigma)\n",
        "    pc = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 0.0001))), U.T)\n",
        "    # Apply ZCA whitening\n",
        "    whitex = np.dot(flatx, pc)\n",
        "    data = np.reshape(whitex, (shape[0], shape[1], shape[2], shape[3]))\n",
        "    return data\n",
        "\n",
        "\n",
        "'''\n",
        "Returns a model without adversarial dropout\n",
        "'''\n",
        "def modelWithRandD(x, n_channels=3):\n",
        "    x = upperBlock(x, n_channels=n_channels)\n",
        "    x = lowerBlock(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "'''\n",
        "Returns a model with adversarial dropout\n",
        "'''\n",
        "def modelWithAdD(x, y, fn_loss=KLDivergenceWithLogits, n_channels=3):\n",
        "    x = upperBlock(x, n_channels=n_channels)\n",
        "    y_no_adD = lowerBlock(x)\n",
        "    loss_no_adD = fn_loss(y_no_adD, y)\n",
        "\n",
        "    # Derivative of loss fn wrt x\n",
        "    DLoss = tf.gradients(loss_no_adD, [x])\n",
        "    DLoss = tf.squeeze(tf.stop_gradient(DLoss)) # Stops backpropagation\n",
        "\n",
        "    Jacobian_approx = DLoss * x\n",
        "    mask = tf.ones_like(x)\n",
        "\n",
        "    x, _ = advDropout(x, mask, Jacobian_approx)\n",
        "    x = lowerBlock(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def CreateBaseModel(x, y, learning_rate=0.001, optimizer=tf.train.AdamOptimizer, n_channels=3):\n",
        "    logit_rand = modelWithRandD(x, n_channels=n_channels)\n",
        "    loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "    opt = optimizer(learning_rate=learning_rate)\n",
        "    gradients = opt.compute_gradients(loss, tf.trainable_variables())\n",
        "    train_op = opt.apply_gradients(gradients)\n",
        "\n",
        "    return train_op, loss, logit_rand\n",
        "\n",
        "\n",
        "'''\n",
        "Create the AdD model for training\n",
        "'''\n",
        "def CreateAdDModel(x, y, learning_rate=0.001, optimizer=tf.train.AdamOptimizer, lmb=0.01, n_channels=3):\n",
        "    logit_rand = modelWithRandD(x, n_channels=n_channels)\n",
        "    logit_rand_loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
        "        # With adversarial dropout\n",
        "        logit_adD = modelWithAdD(x, y, n_channels=n_channels)\n",
        "        logit_adD_loss = CrossEntropyWithLogits(logit_adD, y)\n",
        "\n",
        "        # Total loss\n",
        "        loss = logit_rand_loss + lmb * logit_adD_loss\n",
        "\n",
        "\n",
        "    opt = optimizer(learning_rate=learning_rate)\n",
        "    gradients = opt.compute_gradients(loss, tf.trainable_variables())\n",
        "    train_op = opt.apply_gradients(gradients)        \n",
        "\n",
        "    return train_op, loss, logit_rand\n",
        "\n",
        "\n",
        "def CreateTestModel(x, y, n_channels=3):  \n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
        "        logit_rand = modelWithRandD(x, n_channels=n_channels)\n",
        "        logit_rand_loss = CrossEntropyWithLogits(logit_rand, y)\n",
        "\n",
        "        return logit_rand_loss, logit_rand\n",
        "\n",
        "\n",
        "def Accuracy(logits, labels):\n",
        "    y_pred = tf.argmax(logits, 1)\n",
        "    y_true = tf.argmax(labels, 1)\n",
        "    equality = tf.equal(y_pred, y_true)\n",
        "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
        "    return accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itE0hw-RyRte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Visualization functions"
      ]
    },
    {
      "metadata": {
        "id": "EqYhVsaCyRFO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Uncomment to download graphs from google colab\n",
        "'''\n",
        "from google.colab import files\n",
        "\n",
        "def visualize(trend, param):\n",
        "    name = \"Baseline\" if param['BASELINE'] else \"Adversarial\"\n",
        "    \n",
        "    for key, val in trend.items():\n",
        "        # X axis\n",
        "        x = np.arange(len(val))\n",
        "        # Acc or loss\n",
        "        title = re.sub(\"_\", \" \", key).capitalize()\n",
        "        plt.title(title + \" \" + name)\n",
        "        plt.plot(x, val)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy' if 'acc' in key else 'Loss')\n",
        "        filename = str(key + re.sub(\"{|}|:|'|,| \", \"\", str(param)) + \".png\")\n",
        "        print(filename)\n",
        "        plt.savefig(filename)\n",
        "        files.download(filename)\n",
        "        plt.close()\n",
        "        \n",
        "        \n",
        "def visualize_both(trend_base, trend_adv, param_base, param_adv):\n",
        "    for key in trend_base.keys():\n",
        "        # X axis\n",
        "        x = np.arange(len(trend_base[key]))\n",
        "        # Acc or loss\n",
        "        title = re.sub(\"_\", \" \", key).capitalize()\n",
        "        plt.title(title)\n",
        "        plt.plot(x, trend_base[key], label='Base')\n",
        "        plt.plot(x, trend_adv[key], label='Adversarial')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy' if 'acc' in key else 'Loss')\n",
        "        plt.legend()\n",
        "        filename = str(key + '_both' + \".png\")\n",
        "        print(filename)\n",
        "        plt.savefig(filename)\n",
        "        files.download(filename)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vR2NxY1yYX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creates the graph with input/output nodes for training"
      ]
    },
    {
      "metadata": {
        "id": "nR_HLMEnaO1Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepareTrainingModel(param):\n",
        "    \n",
        "    n_channels = param['CHANNELS']\n",
        "    \n",
        "    with tf.variable_scope('Baseline' if param['BASELINE'] else 'Adversarial'):\n",
        "        # Graph\n",
        "        x_train_ph = tf.placeholder(tf.float32)\n",
        "        x_test_ph = tf.placeholder(tf.float32)\n",
        "        y_train_ph = tf.placeholder(tf.float32)\n",
        "        y_test_ph = tf.placeholder(tf.float32)\n",
        "\n",
        "        train_op, train_loss, train_logit = CreateBaseModel(x_train_ph, y_train_ph, n_channels=n_channels) if param['BASELINE'] else CreateAdDModel(\n",
        "            x_train_ph, y_train_ph, n_channels=n_channels)\n",
        "        test_loss, test_logit = CreateTestModel(x_test_ph, y_test_ph, n_channels=n_channels)\n",
        "\n",
        "        # Accuracy Train\n",
        "        train_accuracy = Accuracy(train_logit, y_train_ph)\n",
        "\n",
        "        # Accuracy Test\n",
        "        test_accuracy = Accuracy(test_logit, y_test_ph)  \n",
        "    \n",
        "    nodes = {\n",
        "        'x_train_ph': x_train_ph,\n",
        "        'x_test_ph': x_test_ph,\n",
        "        'y_train_ph': y_train_ph,\n",
        "        'y_test_ph': y_test_ph,\n",
        "        'train_op': train_op,\n",
        "        'train_loss': train_loss,\n",
        "        'train_logit': train_logit,\n",
        "        'test_logit': test_logit,\n",
        "        'test_loss': test_loss,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy\n",
        "    }\n",
        "    \n",
        "    return nodes\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTfJBUiNyd9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Can perform training incrementally i.e. you do not need to run all epochs at once"
      ]
    },
    {
      "metadata": {
        "id": "ZttTkRv57Uc2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def doTraining(x_train, y_train, x_test, y_test, sess, nodes, param, trend, n_epochs=None):\n",
        "    # Training setup\n",
        "\n",
        "    batch_size = param['BATCH_SIZE']\n",
        "    epochs = param['EPOCHS'] if n_epochs is None else n_epochs\n",
        "    n_channels = x_train.shape[-1]\n",
        "\n",
        "    STEPS = len(x_train) // batch_size if param['STEPS'] is None else param['STEPS']\n",
        "    TEST_STEPS = len(x_test) // batch_size if param['STEPS'] is None else param['STEPS']\n",
        "     \n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        # Train model\n",
        "        acc_train, loss_train = 0, 0\n",
        "        for i in range(STEPS):\n",
        "            _, loss_, acc = sess.run([nodes['train_op'], nodes['train_loss'], nodes['train_accuracy']],\n",
        "                                     feed_dict={nodes['x_train_ph']: x_train[batch_size * i: batch_size * (i + 1)],\n",
        "                                                nodes['y_train_ph']: y_train[batch_size * i: batch_size * (i + 1)]})\n",
        "            acc_train += acc\n",
        "            loss_train += loss_\n",
        "\n",
        "        trend['acc_train_trend'].append(acc_train / STEPS)\n",
        "        trend['loss_train_trend'].append(loss_train / STEPS)\n",
        "\n",
        "        # Test model\n",
        "        acc_test, loss_test = 0, 0\n",
        "        for i in range(TEST_STEPS):\n",
        "            loss_t, acc_t = sess.run([nodes['test_loss'], nodes['test_accuracy']],\n",
        "                                     feed_dict={nodes['x_test_ph']: x_test[batch_size * i: batch_size * (i + 1)],\n",
        "                                                nodes['y_test_ph']: y_test[batch_size * i: batch_size * (i + 1)]})\n",
        "            acc_test += acc_t\n",
        "            loss_test += loss_t\n",
        "\n",
        "        trend['acc_test_trend'].append(acc_test / TEST_STEPS)\n",
        "        trend['loss_test_trend'].append(loss_test / TEST_STEPS)\n",
        "\n",
        "        print('Epoch: {} || Train Loss: {}, Train Acc: {} || Test Loss: {}, Test Accuracy: {}'.format(epoch,\n",
        "                                                                                                      loss_train / STEPS,\n",
        "                                                                                                      acc_train / STEPS,\n",
        "                                                                                                      loss_test / TEST_STEPS,\n",
        "                                                                                                      acc_test / TEST_STEPS))\n",
        "                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lchJVuU-yuue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data I/O and preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "gQ-V2jEK3azu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWM6pXCr3gyy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# with tf.Session() as sess:\n",
        "#     x_train = sess.run(tf.image.rgb_to_grayscale(x_train)) / 255\n",
        "#     x_test = sess.run(tf.image.rgb_to_grayscale(x_test)) / 255\n",
        "x_train, x_test = preprocess(x_train), preprocess(x_test)\n",
        "    \n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHxeKmTxe8Ni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adversarial Dropout training"
      ]
    },
    {
      "metadata": {
        "id": "klD2_w9w7yS4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "param_adv = {\n",
        "    'CHANNELS': 3,\n",
        "    'BATCH_SIZE': 128,\n",
        "    'EPOCHS': 50,\n",
        "    'STEPS': None,\n",
        "    'BASELINE': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inJ-I4gQjY-N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4c8c164-6b9c-4b58-bcf6-b2a32854321a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523922768780,
          "user_tz": 240,
          "elapsed": 264,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Run this to delete default graph w/o having to restart notebook\n",
        "'''\n",
        "# tf.reset_default_graph()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRun this to delete default graph w/o having to restart notebook\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "uKr9xYdbe5nq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nodes_adv = prepareTrainingModel(param_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALKRJKi5fHN6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trend_adv = {\n",
        "    'acc_train_trend': [],\n",
        "    'loss_train_trend': [],\n",
        "    'acc_test_trend': [],\n",
        "    'loss_test_trend': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnQ7IlKvrvp3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess_adv = tf.Session()\n",
        "sess_adv.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSm4U-yJ1dQs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "6695e6aa-9462-4721-ecbe-3593e21f5874",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523930866799,
          "user_tz": 240,
          "elapsed": 8092293,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_adv, nodes_adv, param_adv, trend_adv, n_epochs=50)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 2.5771095373691657, Train Acc: 0.10995592948717949 || Test Loss: 2.4128510921429367, Test Accuracy: 0.11247996794871795\n",
            "Epoch: 1 || Train Loss: 2.2514486991442166, Train Acc: 0.1556690705128205 || Test Loss: 2.2027685122612195, Test Accuracy: 0.18990384615384615\n",
            "Epoch: 2 || Train Loss: 2.0354786573312222, Train Acc: 0.24619391025641027 || Test Loss: 1.9825021685698094, Test Accuracy: 0.31079727564102566\n",
            "Epoch: 3 || Train Loss: 1.801573171065404, Train Acc: 0.3384815705128205 || Test Loss: 2.698420839431958, Test Accuracy: 0.27403846153846156\n",
            "Epoch: 4 || Train Loss: 1.5996402392020592, Train Acc: 0.42175480769230766 || Test Loss: 1.714689551255642, Test Accuracy: 0.42728365384615385\n",
            "Epoch: 5 || Train Loss: 1.425567360719045, Train Acc: 0.4928886217948718 || Test Loss: 1.5586481950221918, Test Accuracy: 0.48127003205128205\n",
            "Epoch: 6 || Train Loss: 1.2638479770758213, Train Acc: 0.5542067307692308 || Test Loss: 1.3721737433702519, Test Accuracy: 0.5361578525641025\n",
            "Epoch: 7 || Train Loss: 1.148532143005958, Train Acc: 0.5989383012820513 || Test Loss: 1.264755979562417, Test Accuracy: 0.5663060897435898\n",
            "Epoch: 8 || Train Loss: 1.057545187840095, Train Acc: 0.6322916666666667 || Test Loss: 1.2452971308659284, Test Accuracy: 0.5914463141025641\n",
            "Epoch: 9 || Train Loss: 0.9799577758862422, Train Acc: 0.6599358974358974 || Test Loss: 1.2610203157632778, Test Accuracy: 0.6065705128205128\n",
            "Epoch: 10 || Train Loss: 0.897556603871859, Train Acc: 0.6900240384615385 || Test Loss: 1.3139889607062707, Test Accuracy: 0.6180889423076923\n",
            "Epoch: 11 || Train Loss: 0.8447686418508872, Train Acc: 0.7063902243589744 || Test Loss: 1.5391714985554035, Test Accuracy: 0.596854967948718\n",
            "Epoch: 12 || Train Loss: 0.8003002123954969, Train Acc: 0.7228565705128205 || Test Loss: 1.2855724852818708, Test Accuracy: 0.6596554487179487\n",
            "Epoch: 13 || Train Loss: 0.7457337547571231, Train Acc: 0.7399238782051282 || Test Loss: 1.8844103369957361, Test Accuracy: 0.6172876602564102\n",
            "Epoch: 14 || Train Loss: 0.7124200506852223, Train Acc: 0.7514222756410256 || Test Loss: 1.510044793287913, Test Accuracy: 0.6643629807692307\n",
            "Epoch: 15 || Train Loss: 0.6785943651046509, Train Acc: 0.7633613782051282 || Test Loss: 1.5117223194012275, Test Accuracy: 0.6888020833333334\n",
            "Epoch: 16 || Train Loss: 0.6478792374714827, Train Acc: 0.7751201923076924 || Test Loss: 1.4830319713323543, Test Accuracy: 0.6801883012820513\n",
            "Epoch: 17 || Train Loss: 0.6256016778640258, Train Acc: 0.7830929487179488 || Test Loss: 1.677634494426923, Test Accuracy: 0.6528445512820513\n",
            "Epoch: 18 || Train Loss: 0.5965679184748576, Train Acc: 0.7919471153846154 || Test Loss: 1.987011663424663, Test Accuracy: 0.6185897435897436\n",
            "Epoch: 19 || Train Loss: 0.5703727994973843, Train Acc: 0.8007211538461538 || Test Loss: 1.7748234837483137, Test Accuracy: 0.6807892628205128\n",
            "Epoch: 20 || Train Loss: 0.5463303447533876, Train Acc: 0.8114583333333333 || Test Loss: 1.5254956629031744, Test Accuracy: 0.6724759615384616\n",
            "Epoch: 21 || Train Loss: 0.5269347831224784, Train Acc: 0.8160857371794872 || Test Loss: 1.6398976720296419, Test Accuracy: 0.6730769230769231\n",
            "Epoch: 22 || Train Loss: 0.5154842530305569, Train Acc: 0.8225360576923076 || Test Loss: 1.6987156302500994, Test Accuracy: 0.6799879807692307\n",
            "Epoch: 23 || Train Loss: 0.4990816042973445, Train Acc: 0.8270232371794872 || Test Loss: 1.9764404999904144, Test Accuracy: 0.6484375\n",
            "Epoch: 24 || Train Loss: 0.47462385908151283, Train Acc: 0.8358573717948717 || Test Loss: 2.049712052712074, Test Accuracy: 0.6830929487179487\n",
            "Epoch: 25 || Train Loss: 0.46780726397648836, Train Acc: 0.8373798076923077 || Test Loss: 2.0335640769738417, Test Accuracy: 0.6805889423076923\n",
            "Epoch: 26 || Train Loss: 0.45281845461099574, Train Acc: 0.8433293269230769 || Test Loss: 1.9513341983159382, Test Accuracy: 0.6994190705128205\n",
            "Epoch: 27 || Train Loss: 0.44272249134687275, Train Acc: 0.8463141025641026 || Test Loss: 1.9485895954645598, Test Accuracy: 0.6861979166666666\n",
            "Epoch: 28 || Train Loss: 0.43260071044548964, Train Acc: 0.8504407051282051 || Test Loss: 2.0247386457064214, Test Accuracy: 0.6893028846153846\n",
            "Epoch: 29 || Train Loss: 0.4167275363054031, Train Acc: 0.8571915064102564 || Test Loss: 2.0843830612989573, Test Accuracy: 0.6985176282051282\n",
            "Epoch: 30 || Train Loss: 0.4164645534677383, Train Acc: 0.8557491987179487 || Test Loss: 2.0501242600954495, Test Accuracy: 0.6834935897435898\n",
            "Epoch: 31 || Train Loss: 0.3961171929652874, Train Acc: 0.8615985576923076 || Test Loss: 2.4451885253955155, Test Accuracy: 0.6737780448717948\n",
            "Epoch: 32 || Train Loss: 0.3863720967219426, Train Acc: 0.8653846153846154 || Test Loss: 2.1496515350464063, Test Accuracy: 0.7106370192307693\n",
            "Epoch: 33 || Train Loss: 0.37765637544485237, Train Acc: 0.8694511217948718 || Test Loss: 2.410940795372694, Test Accuracy: 0.6665665064102564\n",
            "Epoch: 34 || Train Loss: 0.38178167186486417, Train Acc: 0.8681290064102564 || Test Loss: 2.079608460267385, Test Accuracy: 0.7157451923076923\n",
            "Epoch: 35 || Train Loss: 0.3679450116860561, Train Acc: 0.871854967948718 || Test Loss: 2.815341148620997, Test Accuracy: 0.6724759615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 || Train Loss: 0.368885912383214, Train Acc: 0.8725761217948718 || Test Loss: 2.901487695865142, Test Accuracy: 0.6588541666666666\n",
            "Epoch: 37 || Train Loss: 0.3580057885020207, Train Acc: 0.8780248397435897 || Test Loss: 2.8073677328916697, Test Accuracy: 0.6696714743589743\n",
            "Epoch: 38 || Train Loss: 0.3486704012904412, Train Acc: 0.87890625 || Test Loss: 2.6595843709432163, Test Accuracy: 0.6926081730769231\n",
            "Epoch: 39 || Train Loss: 0.35195534794758526, Train Acc: 0.8795272435897435 || Test Loss: 2.2024638744500966, Test Accuracy: 0.7007211538461539\n",
            "Epoch: 40 || Train Loss: 0.3294345988295017, Train Acc: 0.8846754807692307 || Test Loss: 3.093789206101344, Test Accuracy: 0.6664663461538461\n",
            "Epoch: 41 || Train Loss: 0.32800829337957577, Train Acc: 0.8884014423076924 || Test Loss: 2.6140012053342967, Test Accuracy: 0.698417467948718\n",
            "Epoch: 42 || Train Loss: 0.32935327536020526, Train Acc: 0.8871394230769231 || Test Loss: 3.0422634726915603, Test Accuracy: 0.6743790064102564\n",
            "Epoch: 43 || Train Loss: 0.3288330600047723, Train Acc: 0.8871794871794871 || Test Loss: 2.6920930315286684, Test Accuracy: 0.6813902243589743\n",
            "Epoch: 44 || Train Loss: 0.32057502021392187, Train Acc: 0.8896434294871794 || Test Loss: 2.767442469413464, Test Accuracy: 0.6810897435897436\n",
            "Epoch: 45 || Train Loss: 0.3158510624216153, Train Acc: 0.8922876602564103 || Test Loss: 2.7220828991669874, Test Accuracy: 0.7081330128205128\n",
            "Epoch: 46 || Train Loss: 0.30695300644788986, Train Acc: 0.8936899038461539 || Test Loss: 3.477142389004047, Test Accuracy: 0.6645633012820513\n",
            "Epoch: 47 || Train Loss: 0.30389107060738096, Train Acc: 0.895292467948718 || Test Loss: 2.631476486340547, Test Accuracy: 0.7080328525641025\n",
            "Epoch: 48 || Train Loss: 0.3088312017611968, Train Acc: 0.8945112179487179 || Test Loss: 2.634013989032843, Test Accuracy: 0.7052283653846154\n",
            "Epoch: 49 || Train Loss: 0.29364461986682355, Train Acc: 0.8995192307692308 || Test Loss: 3.072456936041514, Test Accuracy: 0.6941105769230769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MOTkA8amjDQy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('adv_trend.json', 'w') as fp:\n",
        "    json.dump(trend_adv, fp)\n",
        "files.download('adv_trend.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlfkuFMHXpFn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9be5fcee-c4c3-4c52-fa9a-58020ad6f1b7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523937748921,
          "user_tz": 240,
          "elapsed": 2466,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize(trend_adv, param_adv)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "loss_train_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "acc_test_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n",
            "loss_test_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINEFalse.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXLHPa13bsP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline Training"
      ]
    },
    {
      "metadata": {
        "id": "VaJHqe25bud3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "param_base = {\n",
        "    'CHANNELS': 3,\n",
        "    'BATCH_SIZE': 128,\n",
        "    'EPOCHS': 50,\n",
        "    'STEPS': None,\n",
        "    'BASELINE': True\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_1a-gb_byBP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nodes_base = prepareTrainingModel(param_base)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "390LlVp2b2gI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trend_base = {\n",
        "    'acc_train_trend': [],\n",
        "    'loss_train_trend': [],\n",
        "    'acc_test_trend': [],\n",
        "    'loss_test_trend': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vrlfTDnab6WI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess_base = tf.Session()\n",
        "sess_base.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbHu1L1pc3-O",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "ae6a0b37-92a5-4f46-edc9-1726852294f0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523936648387,
          "user_tz": 240,
          "elapsed": 4191260,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_base, nodes_base, param_base, trend_base, n_epochs=50)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 44.99179334395971, Train Acc: 0.10512820512820513 || Test Loss: 2.3833683759738236, Test Accuracy: 0.10166266025641026\n",
            "Epoch: 1 || Train Loss: 2.293228856111184, Train Acc: 0.11704727564102564 || Test Loss: 2.3043171075674205, Test Accuracy: 0.1505408653846154\n",
            "Epoch: 2 || Train Loss: 2.265076929483658, Train Acc: 0.13956330128205127 || Test Loss: 2.25803411923922, Test Accuracy: 0.15474759615384615\n",
            "Epoch: 3 || Train Loss: 2.2147713490021537, Train Acc: 0.1685096153846154 || Test Loss: 2.2322454880445433, Test Accuracy: 0.1853966346153846\n",
            "Epoch: 4 || Train Loss: 2.1570706783196867, Train Acc: 0.1953525641025641 || Test Loss: 2.248872834902543, Test Accuracy: 0.2088341346153846\n",
            "Epoch: 5 || Train Loss: 2.1051469075374114, Train Acc: 0.22313701923076923 || Test Loss: 2.2102826711459036, Test Accuracy: 0.23046875\n",
            "Epoch: 6 || Train Loss: 2.060809125655737, Train Acc: 0.24026442307692308 || Test Loss: 2.588299158291939, Test Accuracy: 0.19921875\n",
            "Epoch: 7 || Train Loss: 1.9980287625239446, Train Acc: 0.26282051282051283 || Test Loss: 2.4711765356552906, Test Accuracy: 0.21294070512820512\n",
            "Epoch: 8 || Train Loss: 1.9417985644095983, Train Acc: 0.2835136217948718 || Test Loss: 2.309221211152199, Test Accuracy: 0.24138621794871795\n",
            "Epoch: 9 || Train Loss: 1.876740641777332, Train Acc: 0.316005608974359 || Test Loss: 2.1144965428572435, Test Accuracy: 0.2975761217948718\n",
            "Epoch: 10 || Train Loss: 1.8016272309498909, Train Acc: 0.34324919871794873 || Test Loss: 2.091522528575017, Test Accuracy: 0.33353365384615385\n",
            "Epoch: 11 || Train Loss: 1.7283752988546321, Train Acc: 0.37568108974358977 || Test Loss: 1.9775904248922298, Test Accuracy: 0.3870192307692308\n",
            "Epoch: 12 || Train Loss: 1.6711640740052247, Train Acc: 0.4010416666666667 || Test Loss: 1.893262227376302, Test Accuracy: 0.4221754807692308\n",
            "Epoch: 13 || Train Loss: 1.6118844062854083, Train Acc: 0.4243389423076923 || Test Loss: 1.8990754225315192, Test Accuracy: 0.42578125\n",
            "Epoch: 14 || Train Loss: 1.5549789410371047, Train Acc: 0.4477764423076923 || Test Loss: 1.7580411663422217, Test Accuracy: 0.48377403846153844\n",
            "Epoch: 15 || Train Loss: 1.476946392120459, Train Acc: 0.47682291666666665 || Test Loss: 2.033604464469812, Test Accuracy: 0.4538261217948718\n",
            "Epoch: 16 || Train Loss: 1.407980552697793, Train Acc: 0.5021834935897436 || Test Loss: 1.7187053622343602, Test Accuracy: 0.4908854166666667\n",
            "Epoch: 17 || Train Loss: 1.334490313896766, Train Acc: 0.5303886217948718 || Test Loss: 1.6251279604740632, Test Accuracy: 0.5211338141025641\n",
            "Epoch: 18 || Train Loss: 1.2808126657437056, Train Acc: 0.5485376602564103 || Test Loss: 1.6821975646874843, Test Accuracy: 0.5412660256410257\n",
            "Epoch: 19 || Train Loss: 1.2253034272255041, Train Acc: 0.5708733974358975 || Test Loss: 1.569230473958529, Test Accuracy: 0.5617988782051282\n",
            "Epoch: 20 || Train Loss: 1.1556105028360317, Train Acc: 0.5956730769230769 || Test Loss: 1.7461185103807695, Test Accuracy: 0.5330528846153846\n",
            "Epoch: 21 || Train Loss: 1.1001531912730291, Train Acc: 0.6156850961538461 || Test Loss: 1.4245832975094135, Test Accuracy: 0.5658052884615384\n",
            "Epoch: 22 || Train Loss: 1.0559225777784984, Train Acc: 0.6288060897435898 || Test Loss: 1.4626228549541571, Test Accuracy: 0.6063701923076923\n",
            "Epoch: 23 || Train Loss: 1.0104279907850118, Train Acc: 0.6452524038461539 || Test Loss: 1.3631754792653596, Test Accuracy: 0.5790264423076923\n",
            "Epoch: 24 || Train Loss: 0.9626721255290203, Train Acc: 0.6613581730769231 || Test Loss: 1.3728156563563225, Test Accuracy: 0.5802283653846154\n",
            "Epoch: 25 || Train Loss: 0.9276812058228713, Train Acc: 0.6737179487179488 || Test Loss: 1.4667674899101257, Test Accuracy: 0.5845352564102564\n",
            "Epoch: 26 || Train Loss: 0.878040711237834, Train Acc: 0.6916065705128205 || Test Loss: 1.6573683619499207, Test Accuracy: 0.5368589743589743\n",
            "Epoch: 27 || Train Loss: 0.8591774336802653, Train Acc: 0.6979166666666666 || Test Loss: 1.6514097880094478, Test Accuracy: 0.5741185897435898\n",
            "Epoch: 28 || Train Loss: 0.8167058501488124, Train Acc: 0.7130208333333333 || Test Loss: 1.7247052299670684, Test Accuracy: 0.5530849358974359\n",
            "Epoch: 29 || Train Loss: 0.7857280286458822, Train Acc: 0.7239383012820513 || Test Loss: 1.8200185803266673, Test Accuracy: 0.5908453525641025\n",
            "Epoch: 30 || Train Loss: 0.7529631266227135, Train Acc: 0.7337740384615384 || Test Loss: 1.5687413796400413, Test Accuracy: 0.6190905448717948\n",
            "Epoch: 31 || Train Loss: 0.7292234694346403, Train Acc: 0.7432692307692308 || Test Loss: 1.674085734746395, Test Accuracy: 0.610176282051282\n",
            "Epoch: 32 || Train Loss: 0.6977278118714308, Train Acc: 0.7527443910256411 || Test Loss: 1.9050491666182494, Test Accuracy: 0.5985576923076923\n",
            "Epoch: 33 || Train Loss: 0.6694374420703986, Train Acc: 0.766005608974359 || Test Loss: 1.9364546094185267, Test Accuracy: 0.6238982371794872\n",
            "Epoch: 34 || Train Loss: 0.6500855531447973, Train Acc: 0.770332532051282 || Test Loss: 2.0247649550437927, Test Accuracy: 0.6032652243589743\n",
            "Epoch: 35 || Train Loss: 0.6232174822917351, Train Acc: 0.7815304487179487 || Test Loss: 2.0934213873667593, Test Accuracy: 0.6119791666666666\n",
            "Epoch: 36 || Train Loss: 0.6074262939202479, Train Acc: 0.7849959935897436 || Test Loss: 2.023625135421753, Test Accuracy: 0.6153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37 || Train Loss: 0.5819737969300686, Train Acc: 0.7939302884615385 || Test Loss: 2.0561563204496336, Test Accuracy: 0.6394230769230769\n",
            "Epoch: 38 || Train Loss: 0.5578603613070953, Train Acc: 0.8011818910256411 || Test Loss: 2.120261222888262, Test Accuracy: 0.6533453525641025\n",
            "Epoch: 39 || Train Loss: 0.5442426409476843, Train Acc: 0.8080929487179487 || Test Loss: 1.7516240691527343, Test Accuracy: 0.6608573717948718\n",
            "Epoch: 40 || Train Loss: 0.5324783491018491, Train Acc: 0.8145032051282052 || Test Loss: 1.9945228818135383, Test Accuracy: 0.6502403846153846\n",
            "Epoch: 41 || Train Loss: 0.5256997774044673, Train Acc: 0.8159655448717948 || Test Loss: 2.057412557112865, Test Accuracy: 0.6411258012820513\n",
            "Epoch: 42 || Train Loss: 0.49584715832502413, Train Acc: 0.8248597756410256 || Test Loss: 1.9321143886981866, Test Accuracy: 0.6734775641025641\n",
            "Epoch: 43 || Train Loss: 0.48976458547971186, Train Acc: 0.8287059294871795 || Test Loss: 2.45268685848285, Test Accuracy: 0.6215945512820513\n",
            "Epoch: 44 || Train Loss: 0.4857642215796006, Train Acc: 0.8292067307692308 || Test Loss: 2.1984547116817574, Test Accuracy: 0.6557491987179487\n",
            "Epoch: 45 || Train Loss: 0.4647630239908512, Train Acc: 0.8359575320512821 || Test Loss: 2.3141500048148327, Test Accuracy: 0.6607572115384616\n",
            "Epoch: 46 || Train Loss: 0.45979971388975777, Train Acc: 0.8398036858974359 || Test Loss: 2.7420066044880795, Test Accuracy: 0.6409254807692307\n",
            "Epoch: 47 || Train Loss: 0.4463726464372415, Train Acc: 0.842608173076923 || Test Loss: 2.5456736103082314, Test Accuracy: 0.6507411858974359\n",
            "Epoch: 48 || Train Loss: 0.42873840756141224, Train Acc: 0.8500200320512821 || Test Loss: 2.6242581590628014, Test Accuracy: 0.6529447115384616\n",
            "Epoch: 49 || Train Loss: 0.42149453254846425, Train Acc: 0.852323717948718 || Test Loss: 2.745464884317838, Test Accuracy: 0.6302083333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BuZBeP_Fc-h2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('base_trend.json', 'w') as fp:\n",
        "    json.dump(trend_base, fp)\n",
        "files.download('base_trend.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsSFXhRotGdV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "267c7c96-769f-4c6b-e973-69650b30a490",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523939650812,
          "user_tz": 240,
          "elapsed": 2518,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize(trend_base, param_base)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_train_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINETrue.png\n",
            "loss_train_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINETrue.png\n",
            "acc_test_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINETrue.png\n",
            "loss_test_trendCHANNELS3BATCH_SIZE128EPOCHS50STEPSNoneBASELINETrue.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5kDIKFYytJn8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "visualize_both(trend_base, trend_adv, param_base, param_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnqffYuvzANK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trying more epochs for baseline"
      ]
    },
    {
      "metadata": {
        "id": "ep-ieptUzHAV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1c49aa61-4432-49a9-bf40-62013b2dc3b6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523939532599,
          "user_tz": 240,
          "elapsed": 1255242,
          "user": {
            "displayName": "Nabil Chowdhury",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103307151896729854616"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doTraining(x_train, y_train, x_test, y_test, sess_base, nodes_base, param_base, trend_base, n_epochs=15)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Train Loss: 0.4114689419666926, Train Acc: 0.8565705128205128 || Test Loss: 2.62478596277726, Test Accuracy: 0.6821915064102564\n",
            "Epoch: 1 || Train Loss: 0.4116022842434736, Train Acc: 0.8560296474358975 || Test Loss: 2.397842292602246, Test Accuracy: 0.6944110576923077\n",
            "Epoch: 2 || Train Loss: 0.40900135078491306, Train Acc: 0.8569711538461539 || Test Loss: 2.573611721014365, Test Accuracy: 0.6738782051282052\n",
            "Epoch: 3 || Train Loss: 0.3950696151990157, Train Acc: 0.8607371794871795 || Test Loss: 2.2602377350513754, Test Accuracy: 0.7008213141025641\n",
            "Epoch: 4 || Train Loss: 0.3882401616909565, Train Acc: 0.864863782051282 || Test Loss: 2.585665913728567, Test Accuracy: 0.6643629807692307\n",
            "Epoch: 5 || Train Loss: 0.37742966432601976, Train Acc: 0.8680889423076923 || Test Loss: 2.890182140545967, Test Accuracy: 0.6627604166666666\n",
            "Epoch: 6 || Train Loss: 0.3734817562194971, Train Acc: 0.8680889423076923 || Test Loss: 3.031246014130421, Test Accuracy: 0.6494391025641025\n",
            "Epoch: 7 || Train Loss: 0.359975000566397, Train Acc: 0.8758413461538461 || Test Loss: 2.6715997625619936, Test Accuracy: 0.6796875\n",
            "Epoch: 8 || Train Loss: 0.35318817286155163, Train Acc: 0.8778245192307692 || Test Loss: 2.641043097544939, Test Accuracy: 0.6655649038461539\n",
            "Epoch: 9 || Train Loss: 0.36321620106315, Train Acc: 0.875 || Test Loss: 2.507852470263457, Test Accuracy: 0.6934094551282052\n",
            "Epoch: 10 || Train Loss: 0.3420440094211163, Train Acc: 0.8801282051282051 || Test Loss: 2.940065249418601, Test Accuracy: 0.6860977564102564\n",
            "Epoch: 11 || Train Loss: 0.3411940868466328, Train Acc: 0.8813100961538461 || Test Loss: 2.460312461241698, Test Accuracy: 0.6845953525641025\n",
            "Epoch: 12 || Train Loss: 0.3514612724765753, Train Acc: 0.8767027243589743 || Test Loss: 2.970283636680016, Test Accuracy: 0.6717748397435898\n",
            "Epoch: 13 || Train Loss: 0.33671844261579026, Train Acc: 0.8831330128205128 || Test Loss: 3.029020295693324, Test Accuracy: 0.6650641025641025\n",
            "Epoch: 14 || Train Loss: 0.3231771155427664, Train Acc: 0.8869591346153847 || Test Loss: 3.4224790120736146, Test Accuracy: 0.6385216346153846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f-NqSc4GzLez",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}